# 两种并行集成的树模型
---

## 随机森林

随机森林是以决策树（常用CART树）为基学习器的bagging算法。

当处理**回归问题**时，输出值为各学习器的均值；

当处理**分类问题**时，有两种策略：
- 第一种是原始论文中使用的投票策略，即每个学习器输出一个类别，返回最高预测频率的类别
- 第二种是sklearn中采用的概率聚合策略，即通过各个学习器输出的概率分布先计算样本属于某个类别的平均概率，在对平均的概率分布取argmax以输出最可能的类别。

随机森林中的随机主要来自三个方面：

- 其一为bootstrap抽样导致的训练集随机性
- 其二为每个节点随机选取特征子集进行不纯度计算的随机性
- 其三为当使用随机分割点选取时产生的随机性（此时的随机森林又被称为Extremely Randomized Trees）。

随机森林中特征重要性的计算方式为：

利用相对信息增益来度量单棵树上的各特征特征重要性（与决策树计算方式一致），再通过对所有树产出的重要性得分进行简单平均来作为最终的特征重要性。



## 知识回顾 

什么是偏差和方差分解？偏差是谁的偏差？此处的方差又是指什么？

解答：

泛化误差可以分解为偏差、方差和噪声之和。偏差度量了学习算法的期望预测与真实结果的偏离程度，刻画了学习算法本身的拟合能力。方差度量了同样大小的训练集的变动所导致的学习性能的变化，刻画了数据扰动所造成的影响。

相较于使用单个模型，bagging和boosting方法有何优势？

解答：

bagging可以降低整体模型的方差，boosting可以降低整体模型的偏差。

请叙述stacking的集成流程，并指出blending方法和它的区别。

什么是随机森林的oob得分？

解答：

      随机森林由于每一个基学习器使用了重复抽样得到的数据集进行训练，因此总存在比例大约为的数据集没有参与训练，我们把这一部分数据称为out-of-bag样本，简称oob样本。此时，对每一个基学习器训练完毕后，我们都对oob样本进行预测，每个样本对应的oob_prediction_值为所有没有采样到该样本进行训练的基学习器预测结果均值。在得到所有样本的oob_prediction_后，对于回归问题，使用r2_score来计算对应的oob_score_，而对于分类问题，直接使用accuracy_score来计算oob_score_。

随机森林是如何集成多个决策树模型的？

解答：

      当处理回归问题时，输出值为各学习器的均值；当处理分类问题时有两种策略，第一种是原始论文中使用的投票策略，即每个学习器输出一个类别，返回最高预测频率的类别，第二种是sklearn中采用的概率聚合策略，即通过各个学习器输出的概率分布先计算样本属于某个类别的平均概率，在对平均的概率分布取argmax以输出最可能的类别。


请叙述孤立森林的算法原理和流程。


【练习】R2_score和均方误差的区别是什么？它具有什么优势？

 **解答：**
 - MSE（Mean Squared Error）均方误差: 用 **真实值-预测值** 然后平方之后求和平均。又被称为 L2范数损失 。线性回归用$MSE$作为损失函数
   $$
   MSE=\frac{1}{n}\sum^{n}_{i=1}(y_{i}-\hat{y_{i}})^{2}
   $$
```md
    y_preditc=reg.predict(x_test) #reg是训练好的模型
    mse_test=np.sum((y_preditc-y_test)**2)/len(y_test) # 跟数学公式一样的
```   

 - $R^2 score$，即决定系数，反映因变量的全部变异能通过回归关系被自变量解释的比例。计算公式：
$$R^2=1-\frac{SSE}{SST}$$
即
$$R^2 = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}$$
进一步化简
$$R^2 = 1 - \frac{\sum\limits_i(y_i - \hat{y_i})^2 / n}{\sum\limits_i(y_i - \bar{y})^2 / n} = 1 - \frac{MSE}{Var}$$
分子就变成了常用的评价指标均方误差MSE，分母就变成了方差。

对于$R^2$可以通俗地理解为使用均值作为误差基准，看预测误差是否大于或者小于均值基准误差。

R2_score = 1，样本中预测值和真实值完全相等，没有任何误差，表示回归分析中自变量对因变量的解释越好。

R2_score = 0。此时分子等于分母，样本的每项预测值都等于均值。

R2_score不是r的平方，也可能为负数(分子>分母)，模型等于盲猜，还不如直接计算目标变量的平均值。
```
mean_squared_error(y_test,y_preditc)/ np.var(y_test)
```
> 概念回顾：

$y_i$表示真实的观测值，用$\bar{y}$表示真实观测值的平均值，用$\hat{y_i}$表示预测值,则：

均方根误差(RMSE): 
$$
RMSE=\sqrt {\frac{1}{n}\sum^{n}_{i=1}(y_{i}-\hat{y})^{2}}
$$
  
预测值与真实值的误差平方根的均值。  

回归平方和：SSR

$$SSR = \sum_{i=1}^{n}(\hat{y_i} - \bar{y})^2$$

即估计值与平均值的误差，反映自变量与因变量之间的相关程度的偏差平方和

残差平方和：SSE

$$SSE = \sum_{i=1}^{n}(y_i-\hat{y_i} )^2$$

即估计值与真实值的误差，反映模型拟合程度

总离差平方和：SST
$$SST =SSR + SSE= \sum_{i=1}^{n}(y_i - \bar{y})^2$$

即平均值与真实值的误差，反映与数学期望的偏离程度


【练习】假设使用闵氏距离来度量两个嵌入向量之间的距离，此时对叶子节点的编号顺序会对距离的度量结果有影响吗？




## 资料
- https://zhuanlan.zhihu.com/p/390866122
- https://www.cnblogs.com/nxf-rabbit75/p/10415812.html
- https://zhuanlan.zhihu.com/p/36305931