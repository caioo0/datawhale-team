#  机器学习试题集

> 试题集资料：https://datawhalechina.github.io/fun-rec/#/ch04/ch4.1

## 机器学习试题

### **介绍一个最熟悉的机器学习算法**

解答：

 逻辑回归（LR）：假设数据服从[伯努利分布](https://wiki.mbalib.com/wiki/%E4%BC%AF%E5%8A%AA%E5%88%A9%E5%88%86%E5%B8%83)， 通过**[极大似然估计方法](https://zhuanlan.zhihu.com/p/26614750)**，使用**梯度下降**来求解参数，达到**二分类目**的一个模型。我们在考虑把广义线性模型用于分类的时候，需要如何确定逻辑边界，感知机模型用的阶跃函数，但是阶跃函数不可导，不能作为广义线性模型的联系函数。逻辑回归[对数几率函数](https://zhuanlan.zhihu.com/p/112631530)代替阶跃函数。因为对数几率函数是单调可微的一个函数，所以可以作为联系函数。因此逻辑回归本质上还是广义线性模型。

LR的优缺点：

1. 形式简单，可解释性好；
2. 它直接对分类概率进行建模，不需要指导真实数据的分布，这和生成式模型相区别，避免了假设错误带来的问题。
3. 不仅能够预测出类别，还能预测出概率，能够用于很多场景，比如[ctr排序](https://zhuanlan.zhihu.com/p/334890990)中；
4. 对数几率函数任意阶数可导，能够很容易优化；
5. 可以获得特征权重，方便我们进行特征筛选；
6. 训练速度快
7. 它对稀缺特征效果比较好，因为使用的是$w1,w2,w3$本质上的线性模型，稀疏数据能够筛选出不稀疏的重要特征。
8. 模型表达能力有限
9. 样本不均衡很难处理
10. 在非线性可分数据集上性能有限；



