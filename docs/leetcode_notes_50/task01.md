# 一、数据结构与算法

> 关于笔记，主要来自[datawhale-Leetcode算法笔记](https://datawhalechina.github.io/leetcode-notes/#/ch01/01.01/01.01.02-Algorithm-Complexity)

## 1、数据结构与算法

**数据结构是程序的骨架，而算法则是程序的灵魂。**

**程序  = 算法 + 数据结构**

- 算法：解决问题的方法或者过程
- 数据结构：是数据的计算机表示和相应的一组操作
- 程序：算法和数据结构的具体实现

### 1.1 数据结构

> 数据结构（Data Structure）： 带有结构特性的数据元素的集合。

常见数据结构：数组、链表、栈、队列、哈希表、树、堆、图

根据维度分类数据结构可分为 **逻辑结构** 和 **物理结构**

#### 1.1.1 逻辑结构：线性和非线性

逻辑结构：**数据元素之间的逻辑关系。**

> 数组和链表：数据按照顺序依次排列，体现了数据之间的线性关系
>
> 树：数据从顶部向下按层次排列，体现了祖先与后代之间的派生关系
>
> 图：由节点和边构成，反映了复杂的网络关系

逻辑结构分为线性与非线性，非线性数据结构可以进一步被划分为树形结构和网状结构：

- **线性数据结构：**数组、链表、队列、栈、哈希表、元素之间是一对一的顺序关系
- **非线性数据结构：**树、堆、图、哈希表
  - 树形结构：树、堆、哈希表，元素之间是一对多的关系。
  - 网状结构：图、元素之间是多对多的关系。

![image-20231007092741338](.\img\image-20231007092741338.png)

#### 1.1.2 物理结构分为 **连续和分散**

物理结构反映了数据在计算机内存中的存储方式，可分为连续空间（数组）和分散空间存储（链表）。

> 物理结构从底层决定了数据的访问、更新、增删等操作方法，同时在时间效率和空间效率方面呈现出互补的特点。

![image-20231007094537829](.\img\image-20231007094537829.png)

所有的数据结构都是基于数组、链表或两者的组合实现的。

- **基于数组可实现：**栈、队列、哈希表、树、堆、图、矩阵、张量（维度>=3的数组）等。
- **基于链表可实现：**栈、队列、哈希表、树、堆、图等
- 基于数组实现的数据结构称为"**静态数据结构**"。
- 基于链表实现的数据结构称为“**动态数据结构**”。



计算机内有多种存储结构，采用最多的是这两种结构：**「顺序存储结构」**、**「链式存储结构」**。



1. **顺序存储结构**

​    **定义：**将数据元素存放在一片地址连续的存储单元里，数据元素之间的逻辑关系通过数据元素的存储地址来直接反映。

​	**特点：**

	-  在顺序存储结构中，逻辑上相邻的数据元素在物理地址上也必然相邻 。
	-  简单、易理解，且实际占用最少的存储空间。
	-  需要占用一片地址连续的存储单元；并且存储分配要事先进行；另外对于一些操作的时间效率较低（移动、删除元素等操作）。

![image-20230912102143964](.\img\image-20230912102143964.png)

2. **链式存储结构**

   **定义：**将数据元素存放在任意的存储单元里，存储单元可以连续，也可以不连续。

![image-20230912140549440](.\img\image-20230912140549440.png)

链式存储结构中，逻辑上相邻的数据元素在物理地址上可能相邻，可也能不相邻。其在物理地址上的表现是随机的。

链式存储结构中，一般将每个数据元素占用的若干单元的组合称为一个链结点。每个链结点不仅要存放一个数据元素的数据信息，还要存放一个指出这个数据元素在逻辑关系的直接后继元素所在链结点的地址，该地址被称为指针。换句话说，数据元素之间的逻辑关系是通过指针来间接反映的。



**优点：**存储空间不必事先分配，在需要存储空间的时候可以临时申请，不会造成空间的浪费；一些操作的时间效率远比顺序存储结构高（插入、移动、删除元素）。

**缺点：**不仅数据元素本身的数据信息要占用存储空间，指针也需要占用存储空间，链式存储结构比顺序存储结构的空间开销大。

### 1.2 算法

算法（Algorithm）:  解决特定问题求解步骤的准确而完整的描述，在计算中表现为一系列指令的集合，算法代表着用系统的方法描述解决问题的策略机制。

简单而言，**算法**指的是解决问题的方法。

算法可以用自然语言、编程语言（Python、C、C++、Java等）描述，也可以用**伪流程、流程图**来表示。

#### 1.2.1 算法基本特性

- 输入
- 输出
- 有穷性
- 确定性
- 可行性

#### 1.2.2 算法追求的目标

不同的算法成本不同，一个优秀的算法至少应该追求以下两个目标：

1. **所需运行时间更少（时间复杂度更低）**
2. **占用内存空间更小（空间复杂度更低）**

一个好的算法还应该追求以下目标：

1. **正确性**：正确性是指算法能够满足具体问题的需求，程序运行正常，无语法错误，能够通过典型的软件测试，达到预期的需求。
2. **可读性**：可读性指的是算法遵循标识符命名规则，简洁易懂，注释语句恰当，方便自己和他人阅读，便于后期修改和调试。
3. **健壮性**：健壮性指的是算法对非法数据以及操作有较好的反应和处理。

这 3 个目标是算法的基本标准，是所有算法所必须满足的。一般我们对好的算法的评判标准就是上边提到的 **所需运行时间更少（时间复杂度更低）**、**占用内存空间更小（空间复杂度更低）**。

#### 1.2.3 算法效率评估

效率评估方法主要分为两种：**实际测试、理论估算**。

##### 实际测试： 这种评估方式能够反映真实情况，但也存在较大局限性。

理论估算：这种估算方法被称为「渐近复杂度分析 asymptotic complexity analysis」，简称「复杂度分析」。

复杂度分析体现算法运行所需的时间（空间）资源与输入数据大小之间的关系。**它描述了随着输入数据大小的增加，算法执行所需时间和空间的增长趋势**。这个定义有些拗口，我们可以将其分为三个重点来理解。

- “时间和空间资源”分别对应「时间复杂度 time complexity」和「空间复杂度 space complexity」。
- “随着输入数据大小的增加”意味着复杂度反映了算法运行效率与输入数据体量之间的关系。
- “时间和空间的增长趋势”表示复杂度分析关注的不是运行时间或占用空间的具体值，而是时间或空间增长的“快慢”。

**复杂度分析克服了实际测试方法的弊端**，体现在以下两个方面。

- 它独立于测试环境，分析结果适用于所有运行平台。
- 它可以体现不同数据量下的算法效率，尤其是在大数据量下的算法性能。



### 1.3 迭代与递归



### 1.4 数据结构与算法小结

#### 1.4.1 数据结构总结

数据结构分为 **逻辑结构** 和 **物理结构**。

- 逻辑结构分为：**集合结构**、**线性结构**、**树形结构**、**图形结构**。
- 物理结构分为：**顺序存储结构**、**链式存储结构**。

逻辑结构指的是数据之间的 **关系**，物理结构指的是这种关系 **在计算机中的表现形式**。

>  例如：线性表中的「栈」，其数据元素之间的关系是一对一的，除头和尾结点之外的每个结点都有唯一的前驱和唯一的后继，这体现的是逻辑结构。而对于栈中的结点来说，可以使用顺序存储（也就是 **顺序栈**）的方式存储在计算机中，其结构在计算机中的表现形式就是一段连续的存储空间，栈中每个结点和它的前驱结点、后继结点在物理上都是相邻的。当然，栈中的结点也可以使用链式存储（也即是 **链式栈**），每个结点和它的前驱结点、后继结点在物理上不一定相邻，每个结点是靠前驱结点的指针域来进行访问的。

#### 1.4.2 算法总结

**算法** 指的就是解决问题的方法。

算法是一系列的运算步骤，这些运算步骤可以解决特定的问题。

算法拥有 5 个基本特性：**输入**、**输出**、**有穷性**、**确定性**、**可行性**。

算法追求的目标有 5 个：**正确性**、**可读性**、**健壮性**、**所需运行时间更少（时间复杂度更低）**、**占用内存空间更小（空间复杂度更低）**。

## 2、算法复杂度

**定义：**

算法复杂度（Algorithm complexity）： 在问题的输入规模为n的条件下，程序的时间使用情况和空间使用情况。

算法所追求的就是 **所需运行时间更少（时间复杂度更低）**、**占用内存空间更小（空间复杂度更低）**

算法分析，就是从**运行时间情况、空间使用情况**两方面对算法进行分析。

比较算法的两种方法：

1. 事后统计
2. 预先统计（推荐），**不考虑编程语言，计算机运行速度，只关心随着问题规模 $n$ 扩大时，时间开销、空间开销的增长情况**。

>  **问题规模 $n：$** ：算法问题输入的数据量大小。
>
> - 排序算法中：  $n$表示需要排序的元素数量。
> - 查找算法中： $n$ 表示查找范围内的元素总数：比如数组大小、二维矩阵大小、字符串长度、二叉树节点数、图的节点数、图的边界点等。
> - 二进制计算相关算法中： $n$ 表示二进制的展开宽度。

### 2.1 时间复杂度

定义：

**时间复杂度（Time Complexity）**：在问题的输入规模为 $n$ 的条件下，算法运行所需要花费的时间，可以记作为 $T(n)$。

**基本操作** ：算法执行中的每一条语句。每一次基本操作都可在常数时间内完成。基本操作是一个运行时间不依赖于操作数的操作。

给定一个输入大小为$n$的函数：

```python
def algorithm(n):
    fact = 1                +++++ 1 
    // 循环 n 次 
    for i in range(1,n+1):  +++++ 1（每轮都执行i ++ ）
        fact *= i			+++++ 1
    return fact 			+++++ 1 
```

上述算法的执行次数： $2n+2$ ,用f(n)表示： $f(n) = 2n +2$



**时间复杂度：**$T(n) = O(f(n))$。 它表示的是随着问题规模 n 的增大，算法执行时间的增长趋势跟  $f(n)$相同。

$O$是一种渐进符号，$T(n)$称作算法的渐进时间复杂度（Asymptotic Time Complexity）,简称为时间复杂度。

时间复杂度分析本质上是计算“操作数量函数（T(n)）”的渐进上界， 具有明确的数学定义：

> 若存在正实数c和实数$n_0$,使得对于所有的$ n> n_0$ ,均有$T(n) \leqslant c.f(n)$,则可认为$f(n)$给出了$T(n)$的一个渐进上界，记为$ T(n) = 0(f(n))$。

#### 2.1.1 渐进符号

> 渐进符号（Asymptotic Symbol）:刻画函数的增长速度，并且只保留**最高阶幂**。忽略**低阶幂**、**系数**、**常量**等。

经常用到的渐进符号有三种： **Θ 渐进紧确界符号、$O$渐进上界符号、Ω 渐进下界符号**。

#### 2.1.2 推算方法

渐近上界的数学味儿有点重，如果你感觉没有完全理解，也无须担心。因为在实际使用中，我们只需要掌握推算方法，数学意义就可以逐渐领悟。

确定 $f(n)$之后，我们便可得到时间复杂度 $O(f(n))$ 。那么如何确定渐近上界 $f(n)$呢？总体分为两步：**首先统计操作数量，然后判断渐近上界。**

##### 1.  第一步：统计操作数量

针对代码，逐行从上到下计算即可。然而，由于上述$ c⋅f(n)$ 中的常数项 $c$ 可以取任意大小，**因此操作数量 $T(n)$ 中的各种系数、常数项都可以被忽略**。根据此原则，可以总结出以下计数简化技巧。

1. **忽略 $T(n)$ 中的常数项**。因为它们都与 $n$无关，所以对时间复杂度不产生影响。
2. **省略所有系数**。例如，循环 2$n$次、5$n$+1 次等，都可以简化记为 � 次，因为 � 前面的系数对时间复杂度没有影响。
3. **循环嵌套时使用乘法**。总操作数量等于外层循环和内层循环操作数量之积，每一层循环依然可以分别套用第 `1.` 点和第 `2.` 点的技巧。

给定一个函数，我们可以用上述技巧来统计操作数量。

```python
def algorithm(n: int):
    a = 1      # +0（技巧 1）
    a = a + n  # +0（技巧 1）
    # +n（技巧 2）
    for i in range(5 * n + 1):
        print(0)
    # +n*n（技巧 3）
    for i in range(2 * n):
        for j in range(n + 1):
            print(0)

```

以下公式展示了使用上述技巧前后的统计结果，两者推出的时间复杂度都为$O(n^2)$。


$$
\begin{aligned}
T(n) & = 2n(n + 1) + (5n + 1) + 2 & \text{完整统计 (-.-|||)} \newline
& = 2n^2 + 7n + 3 \newline
T(n) & = n^2 + n & \text{偷懒统计 (o.O)}
\end{aligned}
$$

##### 2. 第二步：判断渐进上界

**时间复杂度由多项式 $T(n)$ 中最高阶的项来决定**。这是因为在 $n$ 趋于无穷大时，最高阶的项将发挥主导作用，其他项的影响都可以被忽略。

一些常见的例子：

![image-20230915180849751](.\img\image-20230915180849751.png)

#### 2.1.3 常见类型

设输入数据大小为 $n$ ，常见的时间复杂度类型如图 2-9 所示（按照从低到高的顺序排列）。
$$
\begin{aligned}
O(1) < O(\log n) < O(n) < O(n \log n) < O(n^2) < O(2^n) < O(n!) \newline
\text{常数阶} < \text{对数阶} < \text{线性阶} < \text{线性对数阶} < \text{平方阶} < \text{指数阶} < \text{阶乘阶}
\end{aligned}
$$
![image-20230915181106231](.\img\image-20230915181106231.png)
$$
图为 常见的时间复杂度类型
$$

##### 1. 常数阶$O(1)$

常数阶的操作数量与输入数据大小 $n$ 无关，即不随着  $n$ 的变化而变化

在以下函数中，尽管操作数量`size`可能很大，但由于其与输入数据大小$n$无关，因此时间复杂度仍为$O(1):$

```python
def constant(n:int) -> int:
	"""常数阶"""
	count = 0 
	size  = 100000
	for _ in range(size):
		count += 1
	return count 
```

##### 2. 线性阶$0(n)$

线性阶的操作数量相对于输入数据大小$n$以线性级别增长。线性阶通常出现在单层循环中：

```python
def linear(n:int) ->int:
	"""线性阶"""
	Count = 0
	fot _ in range(n):
		Count += 1
	return Count 
```

遍历数组和遍历链表等操作的时间复杂度均为$O(n)$,其中$n$ 为数组或链表的长度：

```python
def array_traversal(nums:list[int]) -> int:
	"""线性阶（遍历数组）"""
	count = 0
	# 循环次数与数组长度成正比
	for num in nums:
		count += 1
    return count 
```

值得注意的是，**输入数据大小 $n$ 需根据输入数据的类型来具体确定**。比如在第一个示例中，变量 $n$ 为输入数据大小；在第二个示例中，数组长度 $n$ 为数据大小。

##### 3. 平方阶$O(n^2)$

平方阶的操作数量相对于输入数据大小 $n$ 以平方级别增长。平方阶通常出现在嵌套循环中，外层循环和内层循环都为$O(n)$, 因此总体为$O(n^2)$

```python
def quadratic(n:int) -> int:
	"""平方阶"""
	count = 0
	# 循环次数与数组长度成平方关系
	for i in range(n):
		for j in range(n):
			count +=1
    return count 
```

对比常数阶、线性阶和平方阶三种时间复杂度

![image-20230916103235206](.\img\image-20230916103235206.png)
$$
图为常数阶、线性阶和平方阶的时间复杂度
$$
以冒泡排序为例，外层循环执行$n-1$,内层循环$n-1,n-2,...,2,1$次，平均为$n/2$次，因此时间复杂度为$O((n-1)n/2) = O(n^2)$

```python
def bubble_sort(nums:list[int]) ->int:
	"""平方阶（冒泡排序）"""
	count = 0 # 计数器
	# 外循环：未排序区间为[0,i]
	for i in range(Len(nums) - 1, 0, -1):
		# 内循环：将未排序区间【0，i】中的最大元素交换至该区间的最右端
		for j in range(i):
			if nums[j] > nums[j+1]:
				# 交换 nums[j] 与 nums[j+1]
				tmp: int = nums[j]
				nums[j]  = nums[j+1]
                nums[j+1]  =tmp
                count +=3  # 元素交换包含了3个单位操作
    return count 
```



##### 4. 指数阶$O(2^n)$

 生物学的"细胞分裂"是指数阶增长的典型例子：初始状态为1一个细胞，分裂一轮后变成2个，分裂两轮后4个，一次类推，分类N轮后有$2^n$个细胞。

以下代码模拟了细胞分裂的过程，时间复杂度为 $O(2^n)$ 。

```python
def exponential(n:int)-> int:
	"""指数阶(循环实现)"""
	count = 0
	base = 1
	# 细胞每轮一分为二，形成数列1,2,4,8,...,$2^(n-1)$
	for _ in range(n):
        for _ in range(base):
            count += 1
        base *= 2
    # count = 1 + 2 + 4 + 8 + .. + 2^(n-1) = 2^n - 1
    return count
```

![image-20230916113902545](.\img\image-20230916113902545.png)
$$
图 指数阶的时间复杂度
$$
在实际算法中，指数阶常出现于递归函数中。例如在以下代码中，其递归地一分为二，经过 $n$ 次分裂后停止：

```python
def exp_recur(n:int) ->int:
	"""指数阶（递归实现）"""
	if n ==1
		return 1
	return exp_recur(n - 1) + exp_recur(n - 1) + 1
```

指数阶增长非常迅速，在穷举法（暴力搜索、回溯等）中比较常见。对于数据规模较大的问题，指数阶是不可接受的，通常需要使用动态规划或贪心等算法来解决。

##### 5. 对数阶$O(logn)$

与指数阶相反，对数阶反映了“每轮缩减到一半”的过程，时间复杂度为$O(log_2^n)$,简记为$O(logn)$

```python
def logarithmic(n:float) ->int:
	"""对数阶（循环实现）"""
	count = 0
	while n > 1:
		n = n/2
		count += 1
    return count 
```

![image-20230920171522222](.\img\image-20230920171522222.png)
$$
 对数阶的时间复杂度
$$
递归方法实现：

```python
def log_recur(n: float) -> int:
	"""对数阶（递归实现）"""
	if n <= 1:
		return 0
     return log_recur(n/2) + 1 
```

对数阶常出现于基于分治策略的算法中，体现了“一份为多”和“化繁为简”的算法思想。它增长缓慢，是仅次于常数阶的理想的时间复杂度。

##### 6. 线性对数阶$O(nlogn)$

线性对数阶常出现于嵌套循环中，两层循环的时间复杂度分别为$0log(n)$ 和 $O(n)$。 相关代码如下：

```python
def linear_log_recur(n:float) -> int:
	"""线性对数阶"""
	if n <= 1:
		return 1
    count: int = linear_log_recur(n//2) + line_log_recur(n//2)
    for _ in range(n)
    	count +=1
    return count 
```

![image-20230920180959899](.\img\image-20230920180959899.png)

主流排序算法的时间复杂度通常为 $0(nlog⁡n)$ ，例如快速排序、归并排序、堆排序等。

##### 7. 阶乘阶$O(n!)$

阶乘阶对应数学上的"全排列"问题。给定$n$个互不重复的元素，求其所有可能的排列方案，方案数量为：
$$
n! = n × （n - 1）× （n - 2） ×...× 2 × 1
$$
阶乘通常使用递归实现。

```python
def factorial_recur(n: int) -> int:
    """阶乘阶（递归实现）"""
    if n == 0:
        return 1
    count = 0
    # 从 1 个分裂出 n 个
    for _ in range(n):
        count += factorial_recur(n - 1)
    return count

```

![image-20230920181535787](.\img\image-20230920181535787.png)
$$
 阶乘阶的时间复杂度
$$
请注意，因为当 $n≥4$ 时恒有 $n!>2^n$ ，所以阶乘阶比指数阶增长得更快，在 $n $较大时也是不可接受的。

### 2.2 空间复杂度

空间复杂度 用于衡量算法占用内存空间随着数据变大时的增长趋势。

> **空间复杂度（Space Complexity）**：在问题的输入规模为 $n$ 的条件下，算法所占用的空间大小，可以记作为$S(n)$。一般将 **算法的辅助空间** 作为衡量空间复杂度的标准。

相比于算法的时间复杂度计算来说，算法的空间复杂度更容易计算，主要包括「局部变量（算法范围内定义的变量）所占用的存储空间」和「系统为实现递归（如果算法是递归的话）所使用的堆栈空间」两个部分。

#### 算法相关空间

算法在运行过程中使用的内存空间主要包括以下几种。

- **输入空间**：用于存储算法的输入数据。
- **暂存空间**：用于存储算法在运行过程中的变量、对象、函数上下文等数据。
- **输出空间**：用于存储算法的输出数据。

一般情况下，空间复杂度的统计范围是“暂存空间”加上“输出空间”。

**暂存空间**可以进一步划分为三个部分。

- **暂存数据**：用于保存算法运行过程中的各种常量、变量、对象等。
- **栈帧空间**：用于保存调用函数的上下文数据。系统在每次调用函数时都会在栈顶部创建一个栈帧，函数返回后，栈帧空间会被释放。
- **指令空间**：用于保存编译后的程序指令，在实际统计中通常忽略不计。

在分析一段程序的空间复杂度时，**我们通常统计暂存数据、栈帧空间和输出数据三部分**。

![image-20230920182941085](.\img\image-20230920182941085.png)
$$
算法使用的相关空间
$$

```python
class Node:
    """类"""
    def __init__(self, x: int):
        self.val: int = x                 # 节点值
        self.next: Optional[Node] = None  # 指向下一节点的引用

def function() -> int:
    """函数"""
    # 执行某些操作...
    return 0

def algorithm(n) -> int:  # 输入数据
    A = 0                 # 暂存数据（常量，一般用大写字母表示）
    b = 0                 # 暂存数据（变量）
    node = Node(0)        # 暂存数据（对象）
    c = function()        # 栈帧空间（调用函数）
    return A + b + c      # 输出数据

```



### [2.3 算法复杂度小结](https://datawhalechina.github.io/leetcode-notes/#/ch01/01.01/01.01.02-Algorithm-Complexity?id=算法复杂度总结)

**「算法复杂度」** 包括 **「时间复杂度」** 和 **「空间复杂度」**，用来分析算法执行效率与输入问题规模 $n$ 的增长关系。通常采用 **「渐进符号」** 的形式来表示「算法复杂度」。

常见的时间复杂度有：$O(1)$、$O(\log n)$、$O(n)$、$O(n \times \log n)$、$O(n^2)$、$O(n^3)$、$O(2^n)$、$O(n!)$。

常见的空间复杂度有：$O(1)$、$O(\log n)$、$O(n)$、$O(n^2)$。



## 3、LeetCode练习题5道

#### 1. [2235. 两整数相加](https://leetcode.cn/problems/add-two-integers/)

```python
def twoSum(self, nums: List[int], target: int) -> List[int]:
    numDict = dict()
    for i in range(len(nums)):
        if target-nums[i] in numDict:
            return numDict[target-nums[i]], i
        numDict[nums[i]] = i
    return [0]
```



#### 2. [1929. 数组串联](https://leetcode.cn/problems/concatenation-of-array/)

```python
class Solution:
    def getConcatenation(self, nums: List[int]) -> List[int]:
        nums.extend(nums)
        return nums
```



#### 3.[0771. 宝石与石头](https://leetcode.cn/problems/jewels-and-stones/)

```python
class Solution(object):
    def numJewelsInStones(self, J, S):
        res = 0
        j_arr = []
        for c in J:
            j_arr.append(c)
        for c in S:
            if c in j_arr:
                res += 1
        return res

```



#### 4.[1480. 一维数组的动态和](https://leetcode.cn/problems/running-sum-of-1d-array/)

```python
class Solution(object):
    def runningSum(self, nums):
        """
        :type nums: List[int]
        :rtype: List[int]
        """
        lis = []
        sum = 0
        for i in nums:
            sum+=i
            lis.append(sum)    
        return lis
        

```



#### 5.[0709. 转换成小写字母](https://leetcode.cn/problems/to-lower-case/)

```python
class Solution:
    def toLowerCase(self, str: str) -> str:
        new_ch_list=[]
        for ch in str:
            if 65<=ord(ch)<97:
                new_ch_list.append(chr(ord(ch)+32))
            else:
                new_ch_list.append(ch)
        return "".join(new_ch_list)

```



#### 6.[1672. 最富有客户的资产总量](https://leetcode.cn/problems/richest-customer-wealth/)

```python
class Solution(object):
    def maximumWealth(self, accounts):
        """
        :type accounts: List[List[int]]
        :rtype: int
        """
        maxm = 0
        for i in accounts:
            if maxm < sum(i):
                maxm = sum(i)
        return maxm

```



## 4. 参考资料

1.[Hello-算法](https://www.hello-algo.com/chapter_computational_complexity/time_complexity/#234)

2.[datawhale-Leetcode算法笔记](https://datawhalechina.github.io/leetcode-notes/#/ch01/01.01/01.01.02-Algorithm-Complexity)

