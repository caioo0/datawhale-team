{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f87ec82",
   "metadata": {},
   "source": [
    "# 第七章 PyTorch可视化\n",
    "\n",
    " `torchinfo`\n",
    "\n",
    "## 7.1 可视化网络结构\n",
    "\n",
    "### 7.1.1 使用print函数打印模型基础信息\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f257b58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "model = models.resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5e6025",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet(\n",
    "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  (relu): ReLU(inplace=True)\n",
    "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
    "  (layer1): Sequential(\n",
    "    (0): Bottleneck(\n",
    "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (relu): ReLU(inplace=True)\n",
    "      (downsample): Sequential(\n",
    "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      )\n",
    "    )\n",
    "  )\n",
    "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bb3db4",
   "metadata": {},
   "source": [
    "`print(model)`，只能得出基础构件的信息，既不能显示出每一层的shape，也不能显示对应参数量的大小，为了解决这些问题，我们就需要介绍`torchinfo`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d0ec27",
   "metadata": {},
   "source": [
    "### 7.1.2 使用torchinfo可视化网络结构\n",
    "\n",
    "**torchinfo的安装** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac219314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装方法一\n",
    "#pip install torchinfo \n",
    "# 安装方法二\n",
    "!conda install -c conda-forge torchinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaa70cb",
   "metadata": {},
   "source": [
    "**torchinfo的使用**\n",
    "\n",
    "有时候我们希望观察网络的每个层是什么操作、输出维度、模型的总参数量、训练的参数量、网络的占用内存情况。为了解决这个问题，人们开发了torchinfo工具包\n",
    "\n",
    "torchinfo是由torchsummary和torchsummaryX重构出的库, torchsummary和torchsummaryX已经许久没更新了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24e02e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from torchinfo import summary\n",
    "resnet18 = models.resnet18() # 实例化模型\n",
    "summary(model, (1, 3, 224, 224)) # 1：batch_size 3:图片的通道数 224: 图片的高宽"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2222a8ad",
   "metadata": {},
   "source": [
    "我们可以看到torchinfo提供了更加详细的信息，包括模块信息（每一层的类型、输出shape和参数量）、模型整体的参数量、模型大小、一次前向或者反向传播需要的内存大小等\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575863d4",
   "metadata": {},
   "source": [
    "## 7.2 CNN可视化\n",
    "\n",
    "\n",
    "\n",
    "- 可视化CNN卷积核的方法\n",
    "- 可视化CNN特征图的方法\n",
    "- 可视化CNN显著图（class activation map）的方法\n",
    "\n",
    "\n",
    "### 7.2.1 CNN卷积核可视化\n",
    "\n",
    "PyTorch中可视化卷积核的实现方案，以torchvision自带的VGG11模型为例。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689863ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import vgg11\n",
    "\n",
    "model = vgg11(pretrained=True)\n",
    "print(dict(model.features.named_children()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f705455",
   "metadata": {},
   "source": [
    "卷积核对应的应为卷积层（Conv2d），这里以第“3”层为例，可视化对应的参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a58a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = dict(model.features.named_children())['3']\n",
    "kernel_set = conv1.weight.detach()\n",
    "num = len(conv1.weight.detach())\n",
    "print(kernel_set.shape)\n",
    "for i in range(0,num):\n",
    "    i_kernel = kernel_set[i]\n",
    "    plt.figure(figsize=(20, 17))\n",
    "    if (len(i_kernel)) > 1:\n",
    "        for idx, filer in enumerate(i_kernel):\n",
    "            plt.subplot(9, 9, idx+1) \n",
    "            plt.axis('off')\n",
    "            plt.imshow(filer[ :, :].detach(),cmap='bwr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0c0abd",
   "metadata": {},
   "source": [
    "### 7.2.2 CNN特征图可视化方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5fa352",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hook(object):\n",
    "    def __init__(self):\n",
    "        self.module_name = []\n",
    "        self.features_in_hook = []\n",
    "        self.features_out_hook = []\n",
    "\n",
    "    def __call__(self,module, fea_in, fea_out):\n",
    "        print(\"hooker working\", self)\n",
    "        self.module_name.append(module.__class__)\n",
    "        self.features_in_hook.append(fea_in)\n",
    "        self.features_out_hook.append(fea_out)\n",
    "        return None\n",
    "    \n",
    "\n",
    "def plot_feature(model, idx):\n",
    "    hh = Hook()\n",
    "    model.features[idx].register_forward_hook(hh)\n",
    "    \n",
    "    forward_model(model,False)\n",
    "    print(hh.module_name)\n",
    "    print((hh.features_in_hook[0][0].shape))\n",
    "    print((hh.features_out_hook[0].shape))\n",
    "    \n",
    "    out1 = hh.features_out_hook[0]\n",
    "\n",
    "    total_ft  = out1.shape[1]\n",
    "    first_item = out1[0].cpu().clone()    \n",
    "\n",
    "    plt.figure(figsize=(20, 17))\n",
    "    \n",
    "\n",
    "    for ftidx in range(total_ft):\n",
    "        if ftidx > 99:\n",
    "            break\n",
    "        ft = first_item[ftidx]\n",
    "        plt.subplot(10, 10, ftidx+1) \n",
    "        \n",
    "        plt.axis('off')\n",
    "        #plt.imshow(ft[ :, :].detach(),cmap='gray')\n",
    "        plt.imshow(ft[ :, :].detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12017ae9",
   "metadata": {},
   "source": [
    "这里我们首先实现了一个hook类，之后在plot_feature函数中，将该hook类的对象注册到要进行可视化的网络的某层中。model在进行前向传播的时候会调用hook的__call__函数，我们也就是在那里存储了当前层的输入和输出。这里的features_out_hook 是一个list，每次前向传播一次，都是调用一次，也就是features_out_hook  长度会增加1。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e160cb5",
   "metadata": {},
   "source": [
    "### 7.2.3 CNN class activation map可视化方法\n",
    "\n",
    "CAM系列操作的实现可以通过开源工具包pytorch-grad-cam来实现。\n",
    "\n",
    "- 安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4881ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install grad-cam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae5fe01",
   "metadata": {},
   "source": [
    "一个简单的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d01c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import vgg11,resnet18,resnet101,resnext101_32x8d\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "model = vgg11(pretrained=True)\n",
    "img_path = './dog.jpg'\n",
    "# resize操作是为了和传入神经网络训练图片大小一致\n",
    "img = Image.open(img_path).resize((224,224))\n",
    "# 需要将原始图片转为np.float32格式并且在0-1之间 \n",
    "rgb_img = np.float32(img)/255\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd59bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM,ScoreCAM,GradCAMPlusPlus,AblationCAM,XGradCAM,EigenCAM,FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "target_layers = [model.features[-1]]\n",
    "# 选取合适的类激活图，但是ScoreCAM和AblationCAM需要batch_size\n",
    "cam = GradCAM(model=model,target_layers=target_layers)\n",
    "targets = [ClassifierOutputTarget(preds)]\n",
    "grayscale_cam = cam(input_tensor=img_tensor, targets=targets)\n",
    "grayscale_cam = grayscale_cam[0, :]\n",
    "cam_img = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "print(type(cam_img))\n",
    "Image.fromarray(cam_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fc5e05",
   "metadata": {},
   "source": [
    "### 7.2.4 使用FlashTorch快速实现CNN可视化\n",
    "\n",
    "目前已经有不少开源工具能够帮助我们快速实现CNN可视化。这里我们介绍其中的一个——[FlashTorch](https://github.com/MisaOgura/flashtorch)。\n",
    "\n",
    "- 安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd21256",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install flashtorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d658cd85",
   "metadata": {},
   "source": [
    "- 可视化梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768f9a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download example images\n",
    "# !mkdir -p images\n",
    "# !wget -nv \\\n",
    "#    https://github.com/MisaOgura/flashtorch/raw/master/examples/images/great_grey_owl.jpg \\\n",
    "#    https://github.com/MisaOgura/flashtorch/raw/master/examples/images/peacock.jpg   \\\n",
    "#    https://github.com/MisaOgura/flashtorch/raw/master/examples/images/toucan.jpg    \\\n",
    "#    -P /content/images\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "from flashtorch.utils import apply_transforms, load_image\n",
    "from flashtorch.saliency import Backprop\n",
    "\n",
    "model = models.alexnet(pretrained=True)\n",
    "backprop = Backprop(model)\n",
    "\n",
    "image = load_image('/content/images/great_grey_owl.jpg')\n",
    "owl = apply_transforms(image)\n",
    "\n",
    "target_class = 24\n",
    "backprop.visualize(owl, target_class, guided=True, use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a69b18",
   "metadata": {},
   "source": [
    "可视化卷积核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561ec278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from flashtorch.activmax import GradientAscent\n",
    "\n",
    "model = models.vgg16(pretrained=True)\n",
    "g_ascent = GradientAscent(model.features)\n",
    "\n",
    "# specify layer and filter info\n",
    "conv5_1 = model.features[24]\n",
    "conv5_1_filters = [45, 271, 363, 489]\n",
    "\n",
    "g_ascent.visualize(conv5_1, conv5_1_filters, title=\"VGG16: conv5_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e96d80",
   "metadata": {},
   "source": [
    "## 7.3 使用TensorBoard可视化训练过程\n",
    "\n",
    "- 安装TensorBoard工具\n",
    "- 了解TensorBoard可视化的基本逻辑\n",
    "- 掌握利用TensorBoard实现训练过程可视化\n",
    "- 掌握利用TensorBoard完成其他内容的可视化\n",
    "\n",
    "### 7.3.1 TensorBoard安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742089bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f801a3",
   "metadata": {},
   "source": [
    "也可以使用PyTorch自带的tensorboard工具，此时不需要额外安装tensorboard。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92984bef",
   "metadata": {},
   "source": [
    "## 7.3.2 TensorBoard可视化的基本逻辑\n",
    "\n",
    "Tensorboard的工作流程简单来说是\n",
    "\n",
    "- 将代码运行过程中的，某些你关心的数据保存在一个文件夹中：\n",
    "```md\n",
    "这一步由代码中的writer完成\n",
    "```\n",
    "- 再读取这个文件夹中的数据，用浏览器显示出来：\n",
    "```md\n",
    "这一步通过在命令行运行tensorboard完成。\n",
    "```\n",
    "相关代码：\n",
    "首先导入tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd744f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211d42d0",
   "metadata": {},
   "source": [
    "这里的SummaryWriter的作用就是，将数据以特定的格式存储到刚刚提到的那个文件夹中。\n",
    "\n",
    "首先我们将其实例化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50a837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('./path/to/log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa965122",
   "metadata": {},
   "source": [
    "这里传入的参数就是指向文件夹的路径，之后我们使用这个writer对象“拿出来”的任何数据都保存在这个路径之下。\n",
    "\n",
    "这个对象包含多个方法，比如针对数值，我们可以调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5aebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_scalar(tag, scalar_value, global_step=None, walltime=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaad16d",
   "metadata": {},
   "source": [
    "这里的tag指定可视化时这个变量的名字，scalar_value是你要存的值，global_step可以理解为x轴坐标。\n",
    "\n",
    "举一个简单的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0923a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100)\n",
    "    mAP = eval(model)\n",
    "    writer.add_scalar('mAP', mAP, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf9327b",
   "metadata": {},
   "source": [
    "这样就会生成一个x轴跨度为100的折线图，y轴坐标代表着每一个epoch的mAP。这个折线图会保存在指定的路径下（但是现在还看不到）\n",
    "\n",
    "同理，除了数值，我们可能还会想看到模型训练过程中的图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8996a1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    " writer.add_image(tag, img_tensor, global_step=None, walltime=None, dataformats='CHW')\n",
    " writer.add_images(tag, img_tensor, global_step=None, walltime=None, dataformats='NCHW')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88c9805",
   "metadata": {},
   "source": [
    "### 可视化\n",
    "\n",
    "我们已经将关心的数据拿出来了，接下来我们只需要在命令行运行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dc71d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard --logdir=./path/to/the/folder --port 8123"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc67799",
   "metadata": {},
   "source": [
    "然后打开浏览器，访问地址http://localhost:8123/ 即可。 这里的8123只是随便一个例子，用其他的未被占用端口也没有任何问题，注意命令行的端口与浏览器访问的地址同步。\n",
    "\n",
    "如果发现不显示数据，注意检查一下路径是否正确，命令行这里注意是"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d3261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "--logdir=./path/to/the/folder "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3ad28b",
   "metadata": {},
   "source": [
    "而不是"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6e0812",
   "metadata": {},
   "outputs": [],
   "source": [
    "--logdir= './path/to/the/folder '"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a9ea8a",
   "metadata": {},
   "source": [
    "另一点要注意的是tensorboard并不是实时显示（visdom是完全实时的），而是默认30秒刷新一次。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96077ef9",
   "metadata": {},
   "source": [
    "#### 其他注意项"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a762cfc5",
   "metadata": {},
   "source": [
    "**1.变量归类 ** \n",
    "命名变量的时候可以使用形如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c33c42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2388e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_scalar('loss/loss1', loss1, epoch)\n",
    "writer.add_scalar('loss/loss2', loss2, epoch)\n",
    "writer.add_scalar('loss/loss3', loss3, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a0f394",
   "metadata": {},
   "source": [
    "的格式，这样3个loss就会被显示在同一个section。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b753ced",
   "metadata": {},
   "source": [
    "**2.同时显示多个折线图**\n",
    "假如使用了两种学习率去训练同一个网络，想要比较它们训练过程中的loss曲线，只需要将两个日志文件夹放到同一目录下，并在命令行运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4194b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard --logdir=./path/to/the/root --port 8123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2bdee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "963a08d7",
   "metadata": {},
   "source": [
    "## 7.4 参考资料\n",
    "\n",
    "1. https://github.com/datawhalechina/thorough-pytorch\n",
    "2. https://andrewhuman.github.io/cnn-hidden-layout_search\n",
    "3. https://github.com/jacobgil/pytorch-grad-cam\n",
    "4. https://github.com/MisaOgura/flashtorch\n",
    "2. https://zhuanlan.zhihu.com/p/103630393\n",
    "3. https://github.com/lanpa/tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318463ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch39",
   "language": "python",
   "name": "Pytorch39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
