# 第1、2章概论、模型评估和选择

> 学习笔记来源 datawhale-吃瓜教程，视频：[B站南瓜书教学](https://www.bilibili.com/video/BV1Mh411e7VU/?p=2&vd_source=17fa4774c3617361fe8378798cb196a2)

## 机器学习三观

**1. what 什么是机器学习？**

研究关于”学习算法“的一门学科

**2. why 为什么要学习机器学习？**

从事相关的领域的研究或者工作

**3. how 怎样学机器学习？**

1. 学好高数、线性代数、概率论基础
2. 学的过程中看懂每一步推导过程
3. 深入具体应用方向的研究：（NLP,CV,推荐系统，数据分析，扩散原理，AIGC）


## 基本术语

- **数据集：**记录的集合

- **样本**：”示例“，是关于一个事件或对象的描述。

- **样本空间**：“输入空间”或“属性空间”，样本的特征向量所在的空间为样本空间

- **模型：**指定的假设空间中，确定学习策略，通过优化算法去学习到的**由输入到输出的映射**。

- **算法：**从数据中学的”模型“的具体方法，算法产出的结果称为模型。

- **属性/特征：**反映事件或对象在某方面的表现或性质的事项

- **学习任务分为两大类：**监督学习、无监督学习

- **分布：**概率论中的概率分布

- **独立同分布：**假设样本空间中，全体样本服从一个未知“分布”，获得的每个样本都是独立地从这个分布上采样获得

- **分类：**预测值为离散值的问题

- **回归：**预测值为连续值的问题

- **泛化：**模型对新数据进行分类或预测的能力

- **标记空间：** 标记所在的空间称为”标记空间“或”输出空间“

  

## 归纳偏好

不同的机器学习有不同的偏好，称为**归纳偏好**

同样的问题可以采用不同的机器学习算法得出，具体哪个学的模型更好呢?

常用方法可以采用”奥卡姆剃刀“原则，若有多个假设与观察一致，则选最简单的那个，具体方法基于模型在测试集上的表现来评判模型之间的优劣。

> 数据决定模型的上限，而算法则让模型无限逼近上限



## 经验误差与过拟合
- 错误率：如果在$m$个样本中有$a$个样本分类错误，则错误率为$E=a/m$
- 误差：学习器的实际预测输出与样本的真实输出之间的差异
- 训练误差/经验误差：学习器在训练集上的误差
- 泛化误差：学习器在新样本上的误差
- 精度：精度= 1-错误率
- 过拟合：模型的学习能力相对数据来说过于强大 。 
- 欠拟合：模型的学习的嗯那你相对数据来说过于简单

![image-20231017102431290](.\img\image-20231017102431290.png)

## 评估方法

### 1. 留出法 

- 操作简单，因此最常用

- 概念：直接将数据集$D$划分为两个互斥集合，
  - 一个集合作为训练集$S$，
  - 另一个作为测试集$T$，即$D=S \cup T, S \cap T = \emptyset$，
  - 在$S$上训练出模型后，用$T$来评估其测试误差，作为对泛化误差的估计
- 分层采样：保留类别比例的采样范式
- 常用做法：将大约$2/3 \sim 4/5$的样本用于训练，剩余样本用于测试。

### 2 交叉验证法

- 又称为”**K折交叉验证**“

- 概念：将数据集$D$划分为$k$个大小相同的互斥子集，满足$D=D_1\cup D_2\cup \cdots \cup  D_k, \quad D_i \cap D_j= \emptyset (i \neq j)$，尽可能保持数据分布的一致性，即采用分层抽样的方法获得这些子集。
- 交叉验证法的思想是：
  - 每次用$k-1$个子集的并集作为训练集，余下的那个子集作为测试集，这样就有$K$种训练集/测试集划分的情况，从而可进行$k$次训练和测试，最终返回$k$次测试结果的均值。


- $k$最常用的取值是10，此时称为”10折交叉验证“。
- 交叉验证法本质上是在进行多次留出法，且每次都换不同的子集做测试集，最终让所有样本均至少做 1 次测试样本

![image-20231017103821291](.\img\image-20231017103821291.png)

### 3 自助法
- 概念：给定包含$m$个样本的数据集$D$，
  - 每次随机从$D$中挑选一个样本，将其拷贝放入$D'$，
  - 然后再将该样本放回初始数据集$D$中，使得该样本在下次采样时仍有可能被采到。
  - 重复执行$m$次，就可以得到了包含$m$个样本的数据集$D'$。
  - 可以得知在$m$次采样中，样本始终不被采到的概率取极限为：
$$
\lim _{m \rightarrow \infty}\left(1-\frac{1}{m}\right)^{m} \rightarrow \frac{1}{e} \approx 0.368
$$
&emsp;&emsp;这样，通过自助采样，初始样本集D中大约有36.8%的样本没有出现在$D'$中，于是可以将$D'$作为训练集，$D-D'$作为测试集。



## 调参与最终模型

算法参数是指算法本身的一些参数（也称超参数），例如K近邻个数K,支持向量机的参数$C$。

算法配置好相应参数后进行训练，训练结束会得到一个模型，例如支持向量机最终会得到 **w** 和 *b* 的具体数值（此处不考虑核函数），这就是模型参数，模型配置好相应模型参数后即可对新样本做预测



带有参数的算法一般需要从候选参数配置方案中选择相对于当前数据集的最优参数配置方案，例如支

持向量机的参数 *C*，一般采用的是前面讲到的交叉验证法，但是交叉验证法操作起来较为复杂，实际中更

多采用的是：先用留出法将数据集划分出训练集和测试集，然后再对训练集采用留出法划分出训练集和新

的测试集，称新的测试集为验证集，接着基于验证集的测试结果来调参选出最优参数配置方案，最后将验

证集合并进训练集（训练集数据量够的话也可不合并），用选出的最优参数配置在合并后的训练集上重新

训练，再用测试集来评估训练得到的模型的性能。



## 性能度量

性能度量：对学习器的泛化性能进行评估，反映了任务需求，在对比不同模型的能力时，使用不同的性能度量往往会导致不同的评判结果；

回归任务常用性能度量是 ”均方误差（mean squared error）“:

$$
E(f:D) = \frac{1}{m}\sum_{t=1}^{m}(f{x_i}-y_i)^2
$$
更一般的，对于数据分布$D$和概率密度函数$p(.)$,均方误差可描述为：
$$
E(f:D) = \int_{x \sim D}(f{x_i}-y_i)^2p(x)dx
$$
### 1. 错误率/精度

- 比较常见的两种性能度量，适合二分类，也适用多分类任务 

- 错误率： 分类错误样本数占样本总数的比例。 公式为

  $$E(f ; D)=\frac{1}{m} \sum_{i=1}^m I \left(f(x_i) \neq y_i\right)$$

  

- 精度：分类正确占样本总数的比例。 公式为

  $$
  \begin{aligned} acc(f ; D) 
  &=\frac{1}{m} \sum_{i=1}^{m}I\left(f(x_i)=y_i \right) \\ 
  &=1-E(f ; D) 
  \end{aligned}$$&emsp;&emsp;

### 2.查准率、查全率与F1
- 分类混淆矩阵：  
![image-20231017110443364](.\img\image-20231017110443364.png)
- 查准率$P$：$$P=\frac{TP}{TP+FP}$$
- 查全率$R$：$$R=\frac{TP}{TP+FN}$$


- “P-R曲线”：描述查准/查全率变化的曲线。根据学习器的预测结果（一般为一个实值或概率）对测试样本进行排序，将最可能是“正例”的样本排在前面，最不可能是“正例”的排在后面，按此顺序逐个把样本作为“正例”进行预测，每次计算出当前的P值和R值。

  ![image-20231017110525082](.\img\image-20231017110525082.png)


- F1值：计算查准率与查全率的调和平均值
$$F1=\frac{2 \times P \times R}{P + R} = \frac{2 \times TP}{\text{样例总数 + TP - TN}}$$

### 3. ROC 和 AUC 

AUC-ROC曲线是针对各种阈值设置下的分类问题的性能度量。ROC是概率曲线，AUC表示可分离的程度或测度，它告诉我们多少模型能够区分类别。AUC越高，模型在将0预测为0，将1预测为1时越好。实例中：AUC越高，该模型在区分有疾病和无疾病的患者中越好。

**roc曲线：**接收者操作特征(receiveroperating characteristic), roc曲线上每个点反映着对同一信号刺激的感受性。

横轴：假正类率 (false postive rate, **FPR**)，特异度，划分实例中所有负例占所有负例的比例；TNR=1-FPR。
$$
FPR=\dfrac {FP}{TN+FP}
$$
纵轴：真正类率 ==Recall(true postive rate, **TPR**)，灵敏度，Sensitivity(正类覆盖率)
$$
TPR = \frac{TP}{TP+FN}
$$
用TPR相对FPR绘制ROC曲线，其中TPR在y轴上，FPR在x轴上,如图：

![image-20231017111157725](.\img\image-20231017111157725.png)

**AUC(Area under Curve)：**Roc曲线下的面积，介于0.1和1之间。Auc作为数值可以直观的评价分类器的好坏，值越大越好。
$$
AUC=\dfrac {\sum_{positive}{rank_{i}-\dfrac{M(1+M)}{2}}}{M*N}
$$


![image-20231017111254482](.\img\image-20231017111254482.png)

## 扩展资料

[1].[一文看懂ROC、AUC](https://zhuanlan.zhihu.com/p/81202617)

[2].[机器学习——周志华 （西瓜书）第二章课后习题](https://zhuanlan.zhihu.com/p/42435889)

