{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d5af852",
   "metadata": {},
   "source": [
    "# Part A: 决策树（下）\n",
    "----\n",
    "（本学习笔记来源于[DataWhale-树模型与集成学习](https://github.com/datawhalechina/machine-learning-toy-code)） \n",
    "\n",
    "```md\n",
    "The answer must be in the attempt.\n",
    "你所追寻的答案一定会在努力探索中展现。\n",
    "```\n",
    "\n",
    "\n",
    "本次内容：\n",
    "\n",
    "实现`CART`的分类树算法代码\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1d0ea2",
   "metadata": {},
   "source": [
    "关键知识：`熵`,`信息熵` ,`条件熵`,`信息增益`,`信息增益比`,`基尼系数`，`剪枝`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a3f248",
   "metadata": {},
   "source": [
    "## 一、基本概念知识\n",
    "\n",
    "\n",
    "### 1. 信息熵：\n",
    "\n",
    "1.1 熵：信息的期望值，表示随机变量不确定性的度量.如果待分类的事物可能划分在多个分类之中，则符号$x_{i}$的信息定义为 ：\n",
    "\n",
    "$$\n",
    "    I(x_{i})  = log_{2}\\frac{1}{p(x_{i})} = - log_{2}p(x_{i})\n",
    "$$\n",
    "\n",
    "   其中，$p(x_{i})$是选择该分类的概率\n",
    "\n",
    "1.2 信息熵：计算所有类别所有可能值包含的信息期望值(数学期望)：\n",
    "\n",
    "$$\n",
    "    H = -\\sum^{n}_{i=1}p(x_{i})log_{2}p(x_{i})\n",
    "$$\n",
    "\n",
    "   其中，$p(x_{i})$是选择该分类的概率，$n$是分类的数目。熵越大，随机变量的不确定性就越大。\n",
    "   \n",
    "\n",
    "当熵中的概率由数据估计(特别是最大似然估计)得到时，所对应的熵称为经验熵(empirical entropy)，信息熵又称为经验熵。\n",
    "\n",
    "信息熵公式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "de2bad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数说明：计算给定数据值得信息熵（经验熵）\n",
    "\n",
    "Parameters:\n",
    "    dataSet - 数据集（假定所给数据集向量最后一列为标签（Label）信息）\n",
    "Returns:\n",
    "    commEnt - 信息熵（经验熵）\n",
    "Author:\n",
    "    Jo Choi (297495363@qq.com)\n",
    "Modify:\n",
    "    2021-10-16\n",
    "\"\"\"\n",
    "\n",
    "def calcomEntropy(dataSet,labelIndex):\n",
    "    rowData = len(dataSet)                       # 返回数据集得行数（样本容量|D|）\n",
    "    labelCounts = {}                                 # 保存每个标签（Label）出现次数的字典\n",
    "    for colVec in dataSet:                          # 遍历数据集（获取每个样本标签信息(label),并保存统计数）\n",
    "        currentLabel = colVec[labelIndex]                    # 提取标签（Label）信息，//rowVec[-1] 最后一列为标签\n",
    "        if currentLabel not in labelCounts.keys():  # 判断当前标签（label）没有在统计次数字典，添加初始值为0\n",
    "            labelCounts[currentLabel] = 0 \n",
    "        labelCounts[currentLabel] += 1               # 标签计数\n",
    "         \n",
    "    commEnt = 0.0                                     # 初始化信息熵（经验熵）为 0 \n",
    "    for key in labelCounts:                          # 遍历标签(labelCounts)统计字典 \n",
    "        prob    = float(labelCounts[key]) / rowData  # 计算概率\n",
    "        commEnt -= prob * log(prob,2)                #  遍历计算公式\n",
    "    return commEnt                                   # 返回信息熵（经验熵）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc15245",
   "metadata": {},
   "source": [
    "例如1：\n",
    "有10个数据，一共有两个类别，A类和B类。其中有7个数据属于A类，则该A类的概率即为十分之七。其中有3个数据属于B类，则该B类的概率即为十分之三。\n",
    "我们定义贷款申请样本数据表中的数据为训练数据集D，训练数据集D的经验熵为H(D)，|D|表示其样本容量，及样本个数。设有K个类Ck, = 1,2,3,...,K,|Ck|为属于类Ck的样本个数，因此经验熵公式就可以写为 ：\n",
    "\n",
    "$$\n",
    "    H(D) = -\\sum^{k}_{k=1}\\frac{|C_{k}|}{|D|}log_{2}\\frac{|C_{k}|}{|D|} \n",
    "$$\n",
    "\n",
    "$\\frac{|C_{k}|}{|D|}$ 如同前面公式$p(x_{i})$，代入数据得出经验熵H(D):\n",
    "\n",
    "$$\n",
    "  H(D) = -\\frac{7}{10}log_{2}\\frac{7}{10}-\\frac{3}{10}log_{2}\\frac{3}{10} = 0.88\n",
    "$$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27858bd1",
   "metadata": {},
   "source": [
    "代码实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d87187ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "直接计算信息熵: 0.8812908992306927\n",
      "调用函数计算: 0.8812908992306927\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "\n",
    "# 直接计算\n",
    "H = -log(0.7,2)*0.7 - log(0.3,2)*0.3\n",
    "print(\"直接计算信息熵:\",H)\n",
    "\n",
    "# 调用calcomEntropy函数\n",
    "# 首先转换数据集，这里只用了一个特征\n",
    "dataset = [['A'],['A'],['A'],['A'],['A'],['A'],['A'],['B'],['B'],['B']]\n",
    "print(\"调用函数计算:\",calcomEntropy(dataset,-1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48c4aab",
   "metadata": {},
   "source": [
    "例如2：我们看一组贷款申请样本数据表：\n",
    "\n",
    "![img](https://cuijiahua.com/wp-content/uploads/2017/11/m_2_2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00344c45",
   "metadata": {},
   "source": [
    "根据此公式计算经验熵H(D)，分析贷款申请样本数据表中的数据。最终分类结果只有两类，即放贷和不放贷。根据表中的数据统计可知，在15个数据中，9个数据的结果为放贷，6个数据的结果为不放贷。所以数据集D的经验熵H(D)为："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37510884",
   "metadata": {},
   "source": [
    "$$\n",
    "  H(D) = -\\frac{9}{15}log_{2}\\frac{9}{15}-\\frac{6}{15}log_{2}\\frac{6}{15} = 0.971\n",
    "$$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f068ddeb",
   "metadata": {},
   "source": [
    "我们先转换数据格式： \n",
    "- 年龄：{0,1,2} 0:青年，1:中年，2:老年；\n",
    "- 有工作：{0,1} 0:否，1:是；\n",
    "- 有自己的房子：{0,1} 0:否，1:是；\n",
    "- 信贷情况：{0,1,2} 0:一般，1:好，2:非常好；\n",
    "- 类别(是否给贷款)：{'no','yes'} no:否，yes:是。\n",
    "\n",
    "创建转换后数据集:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "629eb8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataSet():\n",
    "    dataSet = [[0, 0, 0, 0, 'no'],          # 根据表格生成数据集\n",
    "            [0, 0, 0, 1, 'no'],\n",
    "            [0, 1, 0, 1, 'yes'],\n",
    "            [0, 1, 1, 0, 'yes'],\n",
    "            [0, 0, 0, 0, 'no'],\n",
    "            [1, 0, 0, 0, 'no'],\n",
    "            [1, 0, 0, 1, 'no'],\n",
    "            [1, 1, 1, 1, 'yes'],\n",
    "            [1, 0, 1, 2, 'yes'],\n",
    "            [1, 0, 1, 2, 'yes'],\n",
    "            [2, 0, 1, 2, 'yes'],\n",
    "            [2, 0, 1, 1, 'yes'],\n",
    "            [2, 1, 0, 1, 'yes'],\n",
    "            [2, 1, 0, 2, 'yes'],\n",
    "            [2, 0, 0, 0, 'no']]\n",
    "    labels = ['不放贷', '放贷']             # 标签分类属性\n",
    "    return dataSet, labels                 # 返回数据集和标签分类属性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b7d5d8",
   "metadata": {},
   "source": [
    "计算信息熵（经验熵）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd465041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9709505944546686\n"
     ]
    }
   ],
   "source": [
    "# 调用calcomEntropy函数\n",
    "dataset,labels = createDataSet()\n",
    "print(calcomEntropy(dataset,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a200222d",
   "metadata": {},
   "source": [
    "### 条件熵\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc25338",
   "metadata": {},
   "source": [
    "这里直接给出公式：\n",
    "\n",
    "$$\n",
    "H(D|A)  = -\\sum^{n}_{i=1}\\frac{|D_{i}|}{|D|}H(D_{i}) = -\\sum^{n}_{i=1}\\frac{|D_{i}|}{|D|}\\sum^{k}_{k=1}\\frac{|D_{ik}|}{|D_{i}|}log_{2}\\frac{|D_{ik}|}{|D_{i}|} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aea58b",
   "metadata": {},
   "source": [
    "以贷款申请样本数据表为例进行说明。\n",
    "\n",
    "看下年龄这一列的数据，也就是特征A=年龄，一共有三个类别，分别是：`青年`、`中年`和`老年` 刚好是5个，分别占三分之一。\n",
    "\n",
    "有： \n",
    "$$\n",
    "H(D|A=年龄)  =  (\\frac{|D_{青年}|}{D} × H(D_{青年})+(\\frac{|D_{中年}|}{D}×H(D_{中年})+(\\frac{|D_{老年}|}{D}×H(D_{老年}))\n",
    "$$\n",
    "$$\n",
    "         =  (\\frac{5}{15} × H(D_{青年})+(\\frac{5}{15}×H(D_{中年})+(\\frac{5}{15}×H(D_{老年}))\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    " \n",
    " - $H(D_{青年}) = -\\frac{2}{5}log_{2}\\frac{2}{5}-\\frac{3}{5}log_{2}\\frac{3}{5}$ ,青年最终贷款的概率为`五分之二`，不放贷为`五分之三`\n",
    " \n",
    " \n",
    " - $H(D_{中年}) = -\\frac{3}{5}log_{2}\\frac{3}{5}-\\frac{2}{5}log_{2}\\frac{2}{5}$ ,青年最终贷款的概率为`五分之三`，不放贷为`五分之二`\n",
    " \n",
    " \n",
    " - $H(D_{青年}) = -\\frac{4}{5}log_{2}\\frac{4}{5}-\\frac{3}{5}log_{2}\\frac{1}{5}$ ,青年最终贷款的概率为`五分之四`，不放贷为`五分之一`\n",
    " \n",
    " \n",
    " \n",
    " 那么特征=年龄条件熵得出最终数据为：\n",
    " \n",
    " $$\n",
    "       H(D|A=年龄)   =  \\frac{5}{15} ×(-\\frac{2}{5}log_{2}\\frac{2}{5}-\\frac{3}{5}log_{2}\\frac{3}{5})  \n",
    "         + \\frac{5}{15}× (-\\frac{3}{5}log_{2}\\frac{3}{5}-\\frac{2}{5}log_{2}\\frac{2}{5})  \n",
    "         + \\frac{5}{15}×(-\\frac{4}{5}log_{2}\\frac{4}{5}-\\frac{3}{5}log_{2}\\frac{1}{5})   = 0.888\n",
    "$$\n",
    "\n",
    "\n",
    "公式实现：\n",
    "\n",
    "- 选定特征A \n",
    "- 根据选定特征获取分布{A1,A2,A3}\n",
    "- 获取特征分布子数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7bcb251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0个特征条件熵为0.888\n",
      "----\n",
      "第1个特征条件熵为0.647\n",
      "----\n",
      "第2个特征条件熵为0.551\n",
      "----\n",
      "第3个特征条件熵为0.608\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "函数说明：按照给定特征划分数据集　\n",
    "\n",
    "Parameters:\n",
    "    dataSet - 带划分的数据集\n",
    "    axis    - 划分数据集的特征\n",
    "    value   - 需要返回的特征的值\n",
    "Returns:\n",
    "    retDataSet - 划分特征子数据集\n",
    "Author:\n",
    "    Jo Choi (297495363@qq.com)\n",
    "Modify:\n",
    "    2021-10-16\n",
    "\"\"\"\n",
    "def splitDataSet(dataSet,axis,value):\n",
    "    retDataSet = []                                 #  创建返回的数据集列表\n",
    "    for colVec in dataSet:                         # 遍历数据集\n",
    "        if colVec[axis] ==value:                   # 判断符合条件的\n",
    "            reduceFeatVec = colVec[:axis]          # 去掉axis特征，返回[0:axis)元素数据\n",
    "            reduceFeatVec.extend(colVec[axis+1:])  # 追加后面的特征数据\n",
    "            retDataSet.append(reduceFeatVec)\n",
    "    return retDataSet                             # 返回特征划分数据集\n",
    "\n",
    "\"\"\"\n",
    "函数说明：计算选定特征数据集的条件熵　\n",
    "\n",
    "Parameters:\n",
    "    dataSet - 所有数据集\n",
    "    labelIndex - 标签索引 \n",
    "Returns:\n",
    "    retDataSet - 返回每个特征的条件熵\n",
    "Author:\n",
    "    Jo Choi (297495363@qq.com)\n",
    "Modify:\n",
    "    2021-10-16\n",
    "\"\"\"\n",
    "def conditionalEnt(dataSet,labelIndex):\n",
    "    numFeatures = len(dataset[0])-1           # 特征数，最后一个为标签值\n",
    "    retDataSet = []\n",
    "    for i in range(numFeatures):\n",
    "        featList = [rowdata[i] for rowdata in dataset]  # 获取dataSet的第i个所有特征数\n",
    "        uniqueVals = set(featList)                       # 创建set集合{}，去重\n",
    "        conditEnt = 0.0                                  # 初始化特征条件熵\n",
    "        for value in uniqueVals:\n",
    "            subdataSet= splitDataSet(dataset,i,value)    # 划分后的子集（subdataSet）\n",
    "            prob = len(subdataSet)/float(len(dataset))   # 子集的概率 \n",
    "            conditEnt += prob * calcomEntropy(subdataSet,labelIndex)# 根据公式计算条件熵 子集占所有数据集概率 叉× 子集信息熵 （叠加）\n",
    "        retDataSet.append(conditEnt)\n",
    "\n",
    "    return retDataSet                             # 返回特征划分数据集\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataset,labels = createDataSet()               # 获取数据集\n",
    "    # 获取条件熵\n",
    "    conditEntVec = conditionalEnt(dataset,-1)      # 获取条件熵 \n",
    "    for i,value in (enumerate(conditEntVec)):\n",
    "        print(\"第%d个特征条件熵为%.3f\" % (i, value))    \n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d847b952",
   "metadata": {},
   "source": [
    "### 信息增益 \n",
    "\n",
    "\n",
    "特征𝑨对训练数据集D的信息增益𝒈(𝑫, 𝑨)，定义为集合𝑫的经验熵𝑯(𝑫)与特征𝑨给定条件下𝑫的经验条件熵𝑯(𝑫|𝑨)之差，即：\n",
    "\n",
    "$$\n",
    "g(D,A)  = H(D) - H(D|A)\n",
    "$$\n",
    "\n",
    "在特征选择的过程中，需要选择信息增益值最大的的特征𝑨。\n",
    "\n",
    "\n",
    "**算法 5.1 （信息增益的算法）**\n",
    "\n",
    "输入：训练数据集 D 和 特征 A;  \n",
    "输出：特征 A 对训练数据集 D 的信息增益 $g(D,A)$。  \n",
    "\n",
    "（1）计算数据集 D 的经验熵（信息熵）$H(D)$   \n",
    "（2）计算特征 A 对数据集 D 的经验条件熵（条件熵） ）$H(D|A)$  \n",
    "（3）计算信息增益\n",
    "\n",
    "\n",
    "以贷款申请样本数据表为例,计算每个特征的信息增益：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e413e3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0个特征的增益为0.083\n",
      "----\n",
      "第1个特征的增益为0.324\n",
      "----\n",
      "第2个特征的增益为0.420\n",
      "----\n",
      "第3个特征的增益为0.363\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "def calinfoGain(dataset):\n",
    "    commEntVec = calcomEntropy(dataset,-1)       # 计算信息熵\n",
    "    conditEntVec = conditionalEnt(dataset,-1)    # 计算条件熵\n",
    "    for i,value in enumerate(conditEntVec):   # 遍历特征的条件熵\n",
    "        infoGain = commEntVec - value         # 计算信息增益\n",
    "        print(\"第%d个特征的增益为%.3f\" % (i, infoGain))    \n",
    "        print(\"----\")\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    dataset,labels = createDataSet()\n",
    "    calinfoGain(dataset)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0d4315",
   "metadata": {},
   "source": [
    "### 信息增益比\n",
    "\n",
    "信息增益比算法修正了信息增益算法中会对某一特征取值较多时产生偏向的情况。\n",
    "\n",
    " 信息增益比 = 惩罚参数 * 信息增益\n",
    " \n",
    " 公式：\n",
    " \n",
    " $$\n",
    "    g_{R}(D,A)  = \\frac{g(D,A)}{H_{A}(D)}\n",
    " $$\n",
    " \n",
    " 其中：\n",
    "$$\n",
    " H_{A}(D) = - \\sum^{n}_{i=1}\\frac{|D_{i}|}{|D|}log_{2}\\frac{|D_{i}|}{|D|},n 是特征 A 取值的个数\n",
    " $$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70955309",
   "metadata": {},
   "source": [
    " \n",
    " 以贷款申请样本数据表为例,计算特征{年龄}的信息增益比( 青年=5 ， 中年=5 ， 老年=5)：\n",
    " \n",
    "$$\n",
    " H_{A}(D) = - (\\frac{5}{15}log_{2}\\frac{5}{15} + \\frac{5}{15}log_{2}\\frac{5}{15} + \\frac{5}{15}log_{2}\\frac{5}{15})\n",
    " $$\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b59722e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "直接计算特征熵: 1.584962500721156\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "\n",
    "# 直接计算特征熵\n",
    "H = -log(1/3,2)*1/3 - log(1/3,2)*1/3 - log(1/3,2)*1/3\n",
    "\n",
    "print(\"直接计算特征熵:\",H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2db12064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0个特征的特征熵1.585，信息增益0.083，增益比0.052\n",
      "----\n",
      "第1个特征的特征熵0.918，信息增益0.324，增益比0.352\n",
      "----\n",
      "第2个特征的特征熵0.971，信息增益0.420，增益比0.433\n",
      "----\n",
      "第3个特征的特征熵1.566，信息增益0.363，增益比0.232\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "函数说明：计算给定数据值得信息熵（经验熵）\n",
    "\n",
    "Parameters:\n",
    "    dataSet - 数据集（假定所给数据集向量最后一列为标签（Label）信息）\n",
    "Returns:\n",
    "    commEnt - 信息熵（经验熵）\n",
    "Author:\n",
    "    Jo Choi (297495363@qq.com)\n",
    "Modify:\n",
    "    2021-10-16\n",
    "\"\"\"\n",
    "\n",
    "def calcomEntropy(dataSet,labelIndex):\n",
    "    rowData = len(dataSet)                       # 返回数据集得行数（样本容量|D|）\n",
    "    labelCounts = {}                                 # 保存每个标签（Label）出现次数的字典\n",
    "    for colVec in dataSet:                          # 遍历数据集（获取每个样本标签信息(label),并保存统计数）\n",
    "        currentLabel = colVec[labelIndex]                    # 提取标签（Label）信息，//rowVec[-1] 最后一列为标签\n",
    "        if currentLabel not in labelCounts.keys():  # 判断当前标签（label）没有在统计次数字典，添加初始值为0\n",
    "            labelCounts[currentLabel] = 0 \n",
    "        labelCounts[currentLabel] += 1               # 标签计数\n",
    "         \n",
    "    commEnt = 0.0                                     # 初始化信息熵（经验熵）为 0 \n",
    "    for key in labelCounts:                          # 遍历标签(labelCounts)统计字典 \n",
    "        prob    = float(labelCounts[key]) / rowData  # 计算概率\n",
    "        commEnt -= prob * log(prob,2)                #  遍历计算公式\n",
    "    return commEnt                                   # 返回信息熵（经验熵）\n",
    "\n",
    "\"\"\"\n",
    "函数说明：计算信息增益比\n",
    "\n",
    "Parameters:\n",
    "    dataSet - 数据集\n",
    "    labelindex - 标签索引\n",
    "Returns:\n",
    "    无\n",
    "Author:\n",
    "    Jo Choi (297495363@qq.com)\n",
    "Modify:\n",
    "    2021-10-16\n",
    "\"\"\"\n",
    "\n",
    "def calinfoGainRadio(dataset,labelindex):\n",
    "\n",
    "    commEnt = calcomEntropy(dataset,-1)          # 计算信息熵\n",
    "    conditEntVec = conditionalEnt(dataset,-1)    # 计算条件熵\n",
    "    \n",
    "    for i,value in enumerate(conditEntVec):      # 遍历特征的条件熵\n",
    "        fealEnt = calcomEntropy(dataset,i)       # 计算惩罚系数（特征熵)\n",
    "        infoGain = commEnt - value               # 计算信息增益\n",
    "        \n",
    "        infoGainRadio = float(infoGain)/float(fealEnt)\n",
    "        \n",
    "\n",
    "        print(\"第%d个特征的特征熵%.3f，信息增益%.3f，增益比%.3f\" % (i,fealEnt,infoGain,infoGainRadio))  \n",
    "        print(\"----\")\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    dataset,labels = createDataSet()\n",
    "    calinfoGainRadio(dataset,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6e9f44",
   "metadata": {},
   "source": [
    "## 二、ID3 算法生成决策树\n",
    "\n",
    "ID3 算法的核心是在决策树各个结点上应用信息增益选择特征，递归地构建决策树。\n",
    "\n",
    "具体方法是：从根结点（root node）开始，对结点计算所有可能的特征的信息增益，选择`信息增益最大`的特征作为结点，由该特征的不同取值建立子结点；\n",
    "再对子结点递归地调用以上方法，构建决策树；直到所有特征的信息增益均很小或没有特征可以选择为止。最后得到一棵决策树。\n",
    "\n",
    "ID3 相当于极大似然法进行概率模型的选择。\n",
    "\n",
    "  2.1 算法（ID3 算法）\n",
    " \n",
    "  输入： 训练数据集D,特征值A 阈值 $\\varepsilon$；  \n",
    "  输出： 决策树T。    \n",
    "  （1） 若 D 中所有实例属于同一类$C_{k}$,则 T 为单结点树，并将类 $C_{k}$ 作为该结点的类标记，返回 T；   \n",
    "  （2） 若 $A = \\phi $，则 T 为单结点树，并将 D 中实例数最大的类 $C_{k}$ 作为该结点的类标记，返回 T；    \n",
    "  （3）否则，计算信息增益，选择信息增益最大的特征 $A_{g}$；   \n",
    "  （4）如果 $A_{g}$ 的信息增益小于阈值  $\\varepsilon$ ，则 T 为单结点树，并将 D 中实例树最大的类 $C_{k}$ 作为该结点的类标记，返回 T；  \n",
    "  （5）否则，对 $A_{g}$ 的每一可能值 $a_{i}$，依 $A_{g} = a_{i}$ 将 D 分割为若干非空子集 $D_{i}$， 将 $D_{i}$ 中实例数最大的类作为标记，构建子结点，由结点及其子结点构成树T，返回T；    \n",
    "  （6）对第 $i$ 个子结点，以 $D_{i}$ 为训练集，以 $ A - {A_{g}}$ 为特征集，递归地调用上面步骤，得到子树$T_{i}$,返回T；   \n",
    "  \n",
    "  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ccfaa5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2467498197744391,\n",
       " 'outlook',\n",
       " {'sunny':    humility outlook play  temp  windy\n",
       "  0      high   sunny   no   hot  false\n",
       "  1      high   sunny   no   hot   true\n",
       "  7      high   sunny   no  mild  false\n",
       "  8    normal   sunny  yes  cool  false\n",
       "  10   normal   sunny  yes  mild   true,\n",
       "  'overcast':    humility   outlook play  temp  windy\n",
       "  2      high  overcast  yes   hot  false\n",
       "  6    normal  overcast  yes  cool   true\n",
       "  11     high  overcast  yes  mild   true\n",
       "  12   normal  overcast  yes   hot  false,\n",
       "  'rainy':    humility outlook play  temp  windy\n",
       "  3      high   rainy  yes  mild  false\n",
       "  4    normal   rainy  yes  cool  false\n",
       "  5    normal   rainy   no  cool   true\n",
       "  9    normal   rainy  yes  mild  false\n",
       "  13     high   rainy   no  mild   true})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import log\n",
    "df = pd.read_csv('./data/sample_loan.csv', dtype={'windy': 'str'})\n",
    "\n",
    "def entropy(ele):\n",
    "    probs = [ele.count(i)/len(ele) for i in set(ele)]     # 计算 p(x)\n",
    "    entropy = -sum([prob*log(prob, 2) for prob in probs]) # 计算信息熵 sum(-p(x)log2(x))\n",
    "    return entropy\n",
    "\n",
    "def split_dataframe(data, col):\n",
    "    unique_values = data[col].unique() # 获取唯一性 \n",
    "    result_dict = {elem : pd.DataFrame for elem in unique_values}\n",
    "   \n",
    "    for key in result_dict.keys():\n",
    "        result_dict[key] = data[:][data[col] == key]  \n",
    "    return result_dict\n",
    "\n",
    "\n",
    "def choose_best_col(df, label):\n",
    "    entropy_D = entropy(df[label].tolist())\n",
    "    cols = [col for col in df.columns if col not in [label]]\n",
    "    max_value, best_col = -999, None\n",
    "    max_splited = None\n",
    "    for col in cols:\n",
    "        splited_set = split_dataframe(df, col)\n",
    "        entropy_DA = 0\n",
    "        for subset_col, subset in splited_set.items():\n",
    "            entropy_Di = entropy(subset[label].tolist())\n",
    "            entropy_DA += len(subset)/len(df) * entropy_Di\n",
    "        info_gain = entropy_D - entropy_DA\n",
    "        \n",
    "        if info_gain > max_value:\n",
    "            max_value, best_col = info_gain, col\n",
    "            max_splited = splited_set\n",
    "    return max_value, best_col, max_splited\n",
    "    \n",
    "choose_best_col(df, 'play')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a25ec1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数说明:创建决策树ID3 \n",
    " \n",
    "Parameters:\n",
    "    dataSet - 训练数据集\n",
    "    labels - 分类属性标签\n",
    "    featLabels - 存储选择的最优特征标签\n",
    "Returns:\n",
    "    ID3 - 决策树\n",
    "Author:\n",
    "    Jo Choi (297495363@qq.com)\n",
    "Blog:\n",
    "    http://www.damoshijie.com/\n",
    "Modify:\n",
    "    2021-10-16\n",
    "\"\"\"\n",
    "\n",
    "class ID3Tree:\n",
    "    # 定义一个节点类\n",
    "    class Node:\n",
    "        def __init__(self,name):\n",
    "            self.name = name\n",
    "            self.connections  = {} \n",
    "            \n",
    "        def connect(self,label,node):\n",
    "            self.connections[label] = node\n",
    "    \n",
    "    def __init__(self,data,label) :\n",
    "        self.columns = data.columns\n",
    "        self.data    = data\n",
    "        self.label   = label\n",
    "        self.root    = self.Node(\"Root\")\n",
    "        \n",
    "    # print tree method\n",
    "    def print_tree(self, node, tabs):\n",
    "        print(tabs + node.name)\n",
    "        for connection, child_node in node.connections.items():\n",
    "            print(tabs + \"\\t\" + \"(\" + connection + \")\")\n",
    "            self.print_tree(child_node, tabs + \"\\t\\t\")\n",
    "                        \n",
    "            \n",
    "    def construct_tree(self):\n",
    "        self.construct(self.root,\"\",self.data,self.columns)\n",
    "        \n",
    "    def construct(self,parent_node,parent_connection_label,input_data,columns):\n",
    "        max_value,best_col,max_splited = choose_best_col(input_data[columns], self.label)\n",
    "        \n",
    "        if not best_col:\n",
    "            node = self.Node(input_data[self.label].iloc[0])\n",
    "            parent_node.connect(parent_connection_label,node)\n",
    "            return \n",
    "        \n",
    "        node = self.Node(best_col)\n",
    "        parent_node.connect(parent_connection_label, node)\n",
    "        \n",
    "        new_columns = [col for col in columns if col != best_col]\n",
    "        \n",
    "        for splited_value, splited_data in max_splited.items():\n",
    "            self.construct(node, splited_value, splited_data, new_columns)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "tree1 = ID3Tree(df, 'play')\n",
    "tree1.construct_tree()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ebdb8276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root\n",
      "\t()\n",
      "\t\toutlook\n",
      "\t\t\t(sunny)\n",
      "\t\t\t\thumility\n",
      "\t\t\t\t\t(high)\n",
      "\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t(hot)\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(false)\n",
      "\t\t\t\t\t\t\t\t\t\tno\n",
      "\t\t\t\t\t\t\t\t\t(true)\n",
      "\t\t\t\t\t\t\t\t\t\tno\n",
      "\t\t\t\t\t\t\t(mild)\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(false)\n",
      "\t\t\t\t\t\t\t\t\t\tno\n",
      "\t\t\t\t\t(normal)\n",
      "\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t(cool)\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(false)\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t\t\t\t\t(mild)\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(true)\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t(overcast)\n",
      "\t\t\t\thumility\n",
      "\t\t\t\t\t(high)\n",
      "\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t(hot)\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(false)\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t\t\t\t\t(mild)\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(true)\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t\t\t(normal)\n",
      "\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t(cool)\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(true)\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t\t\t\t\t(hot)\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(false)\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t(rainy)\n",
      "\t\t\t\twindy\n",
      "\t\t\t\t\t(false)\n",
      "\t\t\t\t\t\thumility\n",
      "\t\t\t\t\t\t\t(high)\n",
      "\t\t\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t\t\t(mild)\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t\t\t\t\t(normal)\n",
      "\t\t\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t\t\t(cool)\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t\t\t\t\t\t\t(mild)\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t\t\t(true)\n",
      "\t\t\t\t\t\thumility\n",
      "\t\t\t\t\t\t\t(normal)\n",
      "\t\t\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t\t\t(cool)\n",
      "\t\t\t\t\t\t\t\t\t\tno\n",
      "\t\t\t\t\t\t\t(high)\n",
      "\t\t\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t\t\t(mild)\n",
      "\t\t\t\t\t\t\t\t\t\tno\n"
     ]
    }
   ],
   "source": [
    "tree1.print_tree(tree1.root,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecd3e238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "直接计算特征熵: 0.9709505944546686\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "\n",
    "# 直接计算特征熵\n",
    "H = -log(3/5,2)*(3/5) - log(2/5,2)*2/5 \n",
    "print(\"直接计算特征熵:\",H)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4afb8cb",
   "metadata": {},
   "source": [
    "## 参考：\n",
    "\n",
    "- https://cloud.tencent.com/developer/article/1648827\n",
    "- https://zhuanlan.zhihu.com/p/103136609\n",
    "- https://blog.csdn.net/macanv/article/details/60958585"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844deddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
