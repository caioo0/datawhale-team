# Task04: å·ç§¯ç¥žç»ç½‘ç»œCNN
----
>ï¼ˆæœ¬å­¦ä¹ ç¬”è®°æ¥æºäºŽDataWhale-11æœˆç»„é˜Ÿå­¦ä¹ ï¼š[æ°´å¾ˆæ·±çš„æ·±åº¦å­¦ä¹ å­¦ä¹ åœ°å€](https://datawhalechina.github.io/unusual-deep-learning/#/5.CNN) ,[Bç«™è§†é¢‘è®²è§£](https://www.bilibili.com/video/BV1iq4y197L4?p=3) ï¼‰
```md
å¦‚æžœäººå·¥æ™ºèƒ½æ˜¯ä¸€å—è›‹ç³•ï¼Œ
é‚£ä¹ˆå¼ºåŒ–å­¦ä¹ ï¼ˆ Reinforcement Learningï¼‰æ˜¯è›‹ç³•ä¸Šçš„ä¸€ç²’æ¨±æ¡ƒï¼Œ
ç›‘ç£å­¦ä¹ ï¼ˆSupervised Learningï¼‰æ˜¯å¤–é¢çš„ä¸€å±‚ç³–éœœï¼Œ
æ— ç›‘ç£å­¦ä¹ ï¼ˆ Unsupervised Learningï¼‰åˆ™æ˜¯è›‹ç³•èƒšã€‚
```

**å…¨è¿žæŽ¥ç½‘ç»œ VS å·ç§¯ç½‘ç»œ**

å…¨è¿žæŽ¥ç¥žç»ç½‘ç»œ

- å‚æ•°æ•°é‡å¤ªå¤š 
- æ²¡æœ‰åˆ©ç”¨åƒç´ ä¹‹é—´çš„ä½ç½®ä¿¡æ¯
- ç½‘ç»œå±‚æ•°é™åˆ¶
- æ‰€éœ€å†…å­˜å’Œè®¡ç®—é‡å·¨å¤§ã€‚

å·ç§¯ç¥žç»ç½‘ç»œ

- å±€éƒ¨è¿žæŽ¥: æ¯ä¸ªç¥žç»å…ƒä¸å†å’Œä¸Šä¸€å±‚çš„æ‰€æœ‰ç¥žç»å…ƒç›¸è¿žï¼Œè€Œåªå’Œä¸€å°éƒ¨åˆ†ç¥žç»å…ƒç›¸è¿žã€‚è¿™æ ·å°±å‡å°‘äº†å¾ˆå¤šå‚æ•°ã€‚
- æƒå€¼å…±äº«:ä¸€ç»„è¿žæŽ¥å¯ä»¥å…±äº«åŒä¸€ä¸ªæƒé‡ï¼Œè€Œä¸æ˜¯æ¯ä¸ªè¿žæŽ¥æœ‰ä¸€ä¸ªä¸åŒçš„æƒé‡ï¼Œè¿™æ ·åˆå‡å°‘äº†å¾ˆå¤šå‚æ•°
- ä¸‹é‡‡æ · : ä½¿ç”¨Poolingæ¥å‡å°‘æ¯å±‚çš„æ ·æœ¬æ•°ï¼Œè¿›ä¸€æ­¥å‡å°‘å‚æ•°æ•°é‡ï¼ŒåŒæ—¶è¿˜å¯ä»¥æå‡æ¨¡åž‹çš„é²æ£’æ€§ã€‚




## 1. å·ç§¯ï¼ˆConvolutionï¼‰


å·ç§¯ï¼ˆConvolutionï¼‰ï¼Œä¹Ÿå«è¤¶ç§¯ï¼Œæ˜¯åˆ†æžæ•°å­¦ä¸­ä¸€ç§é‡è¦çš„è¿ç®—ï¼Ž

### 1.1 å·ç§¯åˆ†ç±»:

**è¿žç»­å·ç§¯ï¼š**  

$ (f*g)(n)= \int^{\infty}_{-\infty}f(\tau)g(n-\tau)d\tau ï¼Œ n=\tau + (n-\tau)$


**ç¦»æ•£å·ç§¯ï¼š**  

$ (f*g)(n)= \sum^{\infty}_{\tau=-\infty}f(\tau)g(n-\tau) ï¼Œ n=\tau + (n-\tau)$


**å·ç§¯åº”ç”¨åœºæ™¯**

- ç»Ÿè®¡å­¦ä¸­åŠ æƒå¹³å‡æ³•
- æ¦‚çŽ‡è®ºä¸­ä¸¤ä¸ªç‹¬ç«‹å˜é‡ä¹‹å’Œæ¦‚çŽ‡å¯†åº¦çš„è®¡ç®—
- ä¿¡å·å¤„ç†ä¸­çš„çº¿æ€§ç³»ç»Ÿ
- ç‰©ç†å­¦çš„çº¿æ€§ç³»ç»Ÿ
- å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨(å·ç§¯ç¥žç»ç½‘ç»œ)


å…¶ä»–å·ç§¯ï¼š

- è½¬ç½®å·ç§¯/å¾®æ­¥å·ç§¯ï¼šä½Žç»´ç‰¹å¾æ˜ å°„åˆ°é«˜ç»´ç‰¹å¾

- ç©ºæ´žå·ç§¯ï¼šä¸ºäº†å¢žåŠ è¾“å‡ºå•å…ƒçš„æ„Ÿå—é‡Žï¼Œé€šè¿‡ç»™å·ç§¯æ ¸æ’å…¥â€œç©ºæ´žâ€æ¥å˜ç›¸åœ°å¢žåŠ å…¶å¤§å°ã€‚


å®žé™…åº”ç”¨ä¸­å·ç§¯ç½‘ç»œä¸­çš„å·ç§¯æ ¸å¸¸è§ä¸ºç¦»æ•£å·ç§¯è¿ç®—.




åœ¨ä¿¡å·å¤„ç†æˆ–å›¾åƒå¤„ç†ä¸­ï¼Œç»å¸¸ä½¿ç”¨ä¸€ç»´æˆ–äºŒç»´å·ç§¯ï¼Ž

### 1.2  ä¸€ç»´å·ç§¯

ä¸€ç»´å·ç§¯ç»å¸¸ç”¨åœ¨ä¿¡å·å¤„ç†ä¸­ï¼Œç”¨äºŽè®¡ç®—ä¿¡å·çš„å»¶è¿Ÿç´¯ç§¯. 


å‡è®¾ä¸€ä¸ªä¿¡å·å‘ç”Ÿå™¨æ¯ä¸ªæ—¶åˆ» $ð‘¡$ äº§ç”Ÿä¸€ä¸ªä¿¡å· $ð‘¥_ð‘¡$ï¼Œå…¶ä¿¡æ¯çš„è¡°å‡çŽ‡ä¸º $ð‘¤_ð‘˜$ï¼Œå³åœ¨ $ð‘˜ âˆ’ 1$ ä¸ªæ—¶é—´æ­¥é•¿
åŽï¼Œä¿¡æ¯ä¸ºåŽŸæ¥çš„$ð‘¤_ð‘˜$ å€ï¼Žå‡è®¾$ð‘¤_1 = 1, ð‘¤_2 = 1/2, ð‘¤_3 = 1/4$ï¼Œé‚£ä¹ˆåœ¨æ—¶åˆ» $ð‘¡$ æ”¶åˆ°çš„ä¿¡å· $ð‘¦_ð‘¡$ ä¸ºå½“å‰æ—¶åˆ»äº§ç”Ÿçš„ä¿¡æ¯å’Œä»¥å‰æ—¶åˆ»å»¶è¿Ÿä¿¡æ¯çš„å åŠ 

$$
ð‘¦_ð‘¡ = 1 Ã— ð‘¥_ð‘¡ + 1/2 Ã— ð‘¥_{ð‘¡âˆ’1} + 1/4 Ã— ð‘¥_{ð‘¡âˆ’2}   \\
= ð‘¤_1 Ã— ð‘¥_ð‘¡ + ð‘¤_2 Ã— ð‘¥_{ð‘¡âˆ’1} + ð‘¤_3 Ã— ð‘¥_{ð‘¡âˆ’2}  \\
= \sum^{3}_{ð‘˜=1}ð‘¤_ð‘˜ð‘¥_{ð‘¡âˆ’ð‘˜+1}.
$$

æˆ‘ä»¬æŠŠ$ð‘¤_1, ð‘¤_2, â‹¯$ç§°ä¸º`æ»¤æ³¢å™¨`ï¼ˆFilterï¼‰æˆ–`å·ç§¯æ ¸`ï¼ˆConvolution Kernelï¼‰ï¼Ž

å‡è®¾æ»¤æ³¢å™¨é•¿åº¦ä¸º$ð¾$ï¼Œå®ƒå’Œä¸€ä¸ªä¿¡å·åºåˆ—$ð‘¥_1, ð‘¥_2, â‹¯$çš„**å·ç§¯**ä¸º


$$
ð‘¦_ð‘¡ =  \sum^{k}_{ð‘˜=1}ð‘¤_ð‘˜ð‘¥_{ð‘¡âˆ’ð‘˜+1}.
$$


### 1.3 äºŒç»´å·ç§¯

äºŒç»´å·ç§¯è¿ç®—ï¼šç»™å®šäºŒç»´çš„å›¾åƒ$I$ä½œä¸ºè¾“å…¥ï¼ŒäºŒç»´å·ç§¯æ ¸$K$ï¼Œå·ç§¯è¿ç®—å¯è¡¨ç¤ºä¸º 
$$
S(i,j)=(Iâˆ—K)(i,j)=âˆ‘mâˆ‘nI(iâˆ’m,jâˆ’n)K(m,n)
$$
å·ç§¯æ ¸éœ€è¦è¿›è¡Œä¸Šä¸‹ç¿»è½¬å’Œå·¦å³åè½¬ï¼Œ`å´æ©è¾¾çš„è¯´æ³•ï¼ŒRNNä¸­äºŒç»´å·ç§¯æ ¸å¯ä»¥ä¸å¿…åšä»»ä½•ç¿»è½¬,å¹¶ä¸å½±å“ç»“æžœ`


å·ç§¯é€šå¸¸æœ‰ä¸‰ç§ç±»åž‹ï¼šfullå·ç§¯ã€sameå·ç§¯å’Œvalidå·ç§¯.è¿™é‡Œå°±ä¸å¤šå±•å¼€,æƒ³äº†è§£å¯ä»¥é˜…è¯»ä¹¦ç±:[å›¾è§£æ·±åº¦å­¦ä¹ ä¸Žç¥žç»ç½‘ç»œï¼šä»Žå¼ é‡åˆ°TensorFlowå®žçŽ°](https://github.com/XQLuck/DeepLearning-Notes/blob/master/Books/%E3%80%8A%E5%9B%BE%E8%A7%A3%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%9A%E4%BB%8E%E5%BC%A0%E9%87%8F%E5%88%B0TensorFlow%E5%AE%9E%E7%8E%B0%E3%80%8B_%E5%BC%A0%E5%B9%B3_2018-09-01.pdf)


## 2. å·ç§¯ç¥žç»ç½‘ç»œåŸºæœ¬åŽŸç†

å·ç§¯ç¥žç»ç½‘ç»œçš„åŸºæœ¬ç»“æž„å¤§è‡´åŒ…æ‹¬ï¼š`å·ç§¯å±‚`ã€`æ¿€æ´»å‡½æ•°`ã€`æ± åŒ–å±‚`ã€`å…¨è¿žæŽ¥å±‚`ã€`è¾“å‡ºå±‚`ç­‰ã€‚

### 2.1 å·ç§¯å±‚


å·ç§¯å±‚çš„è¿ç®—è¿‡ç¨‹å¦‚ä¸‹å›¾ï¼Œç”¨ä¸€ä¸ªå·ç§¯æ ¸æ‰«å®Œæ•´å¼ å›¾ç‰‡ï¼š

![img](./images/task04-juanji.gif)

è¿™ä¸ªè¿‡ç¨‹æˆ‘ä»¬å¯ä»¥ç†è§£ä¸ºæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªè¿‡æ»¤å™¨ï¼ˆå·ç§¯æ ¸ï¼‰æ¥è¿‡æ»¤å›¾åƒçš„å„ä¸ªå°åŒºåŸŸï¼Œä»Žè€Œå¾—åˆ°è¿™äº›å°åŒºåŸŸçš„ç‰¹å¾å€¼ã€‚


**æ­¥é•¿ï¼ˆStrideï¼‰**

Strideçš„ä½œç”¨ï¼šæ˜¯æˆå€ç¼©å°å°ºå¯¸ï¼Œè€Œè¿™ä¸ªå‚æ•°çš„å€¼å°±æ˜¯ç¼©å°çš„å…·ä½“å€æ•°ï¼Œæ¯”å¦‚æ­¥å¹…ä¸º2ï¼Œè¾“å‡ºå°±æ˜¯è¾“å…¥çš„1/2ï¼›æ­¥å¹…ä¸º3ï¼Œè¾“å‡ºå°±æ˜¯è¾“å…¥çš„1/3ã€‚ä»¥æ­¤ç±»æŽ¨ã€‚

ã€å·ç§¯æ ¸çš„å¤§å°ä¸€èˆ¬ä¸ºå¥‡æ•° * å¥‡æ•°ã€‘ $1* 1ï¼Œ3* 3ï¼Œ5 * 5ï¼Œ7 * 7$ éƒ½æ˜¯æœ€å¸¸è§çš„ã€‚è¿™æ˜¯ä¸ºä»€ä¹ˆå‘¢ï¼Ÿä¸ºä»€ä¹ˆæ²¡æœ‰ å¶æ•° * å¶æ•°ï¼Ÿ

```md
 å¥‡æ•°å·ç§¯æ ¸ä¸­å¿ƒåªæœ‰ä¸€åˆ—ï¼Œå¯ä»¥æ»¡è¶³ä¸¤è¾¹å¯¹ç§°ï¼Œæ¯”è¾ƒå®¹æ˜“åˆ¤æ–­ã€‚å¥½åƒè·Ÿåž‚ç›´è¾¹ç¼˜å’Œæ°´å¹³è¾¹ç¼˜æœ‰å…³ã€‚
```

**æ•°æ®å¡«å……ï¼ˆpaddingï¼‰**

ä¸¤ç§paddingï¼š

- valid paddingï¼šä¸è¿›è¡Œä»»ä½•å¤„ç†ï¼Œåªä½¿ç”¨åŽŸå§‹å›¾åƒï¼Œä¸å…è®¸å·ç§¯æ ¸è¶…å‡ºåŽŸå§‹å›¾åƒè¾¹ç•Œ
- same paddingï¼šè¿›è¡Œå¡«å……ï¼Œå…è®¸å·ç§¯æ ¸è¶…å‡ºåŽŸå§‹å›¾åƒè¾¹ç•Œï¼Œå¹¶ä½¿å¾—å·ç§¯åŽç»“æžœçš„å¤§å°ä¸ŽåŽŸæ¥çš„ä¸€è‡´


**æ„Ÿå—é‡Ž**

åœ¨å¤„ç†å›¾åƒè¿™æ ·çš„é«˜ç»´åº¦è¾“å…¥æ—¶ï¼Œè®©æ¯ä¸ªç¥žç»å…ƒéƒ½ä¸Žå‰ä¸€å±‚ä¸­çš„æ‰€æœ‰ç¥žç»å…ƒè¿›è¡Œå…¨è¿žæŽ¥æ˜¯ä¸çŽ°å®žçš„ã€‚ç›¸åï¼Œæˆ‘ä»¬è®©æ¯ä¸ªç¥žç»å…ƒåªä¸Žè¾“å…¥æ•°æ®çš„ä¸€ä¸ªå±€éƒ¨åŒºåŸŸè¿žæŽ¥ã€‚è¯¥è¿žæŽ¥çš„ç©ºé—´å¤§å°å«åšç¥žç»å…ƒçš„æ„Ÿå—é‡Žï¼ˆreceptive fieldï¼‰ï¼Œå®ƒçš„å°ºå¯¸æ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼ˆå…¶å®žå°±æ˜¯æ»¤æ³¢å™¨çš„ç©ºé—´å°ºå¯¸ï¼‰ã€‚åœ¨æ·±åº¦æ–¹å‘ä¸Šï¼Œè¿™ä¸ªè¿žæŽ¥çš„å¤§å°æ€»æ˜¯å’Œè¾“å…¥é‡çš„æ·±åº¦ç›¸ç­‰ã€‚éœ€è¦å†æ¬¡å¼ºè°ƒçš„æ˜¯ï¼Œæˆ‘ä»¬å¯¹å¾…ç©ºé—´ç»´åº¦ï¼ˆå®½å’Œé«˜ï¼‰ä¸Žæ·±åº¦ç»´åº¦æ˜¯ä¸åŒçš„ï¼šè¿žæŽ¥åœ¨ç©ºé—´ï¼ˆå®½é«˜ï¼‰ä¸Šæ˜¯å±€éƒ¨çš„ï¼Œä½†æ˜¯åœ¨æ·±åº¦ä¸Šæ€»æ˜¯å’Œè¾“å…¥æ•°æ®çš„æ·±åº¦ä¸€è‡´ï¼Œè¿™ä¸€ç‚¹ä¼šåœ¨ä¸‹é¢ä¸¾ä¾‹å…·ä½“è¯´æ˜Žã€‚


![img](./images/task04-03.jpg)


åœ¨å›¾ 2 ä¸­å±•çŽ°çš„å·ç§¯ç¥žç»ç½‘ç»œçš„ä¸€éƒ¨åˆ†ï¼Œå…¶ä¸­çš„çº¢è‰²ä¸ºè¾“å…¥æ•°æ®ï¼Œå‡è®¾è¾“å…¥æ•°æ®ä½“å°ºå¯¸ä¸º[32x32x3]ï¼ˆæ¯”å¦‚CIFAR-10çš„RGBå›¾åƒï¼‰ï¼Œå¦‚æžœæ„Ÿå—é‡Žï¼ˆæˆ–æ»¤æ³¢å™¨å°ºå¯¸ï¼‰æ˜¯5x5ï¼Œé‚£ä¹ˆå·ç§¯å±‚ä¸­çš„æ¯ä¸ªç¥žç»å…ƒä¼šæœ‰è¾“å…¥æ•°æ®ä½“ä¸­[5x5x3]åŒºåŸŸçš„æƒé‡ï¼Œå…±5x5x3=75ä¸ªæƒé‡ï¼ˆè¿˜è¦åŠ ä¸€ä¸ªåå·®å‚æ•°ï¼‰ã€‚æ³¨æ„è¿™ä¸ªè¿žæŽ¥åœ¨æ·±åº¦ç»´åº¦ä¸Šçš„å¤§å°å¿…é¡»ä¸º3ï¼Œå’Œè¾“å…¥æ•°æ®ä½“çš„æ·±åº¦ä¸€è‡´ã€‚å…¶ä¸­è¿˜æœ‰ä¸€ç‚¹éœ€è¦æ³¨æ„ï¼Œå¯¹åº”ä¸€ä¸ªæ„Ÿå—é‡Žæœ‰75ä¸ªæƒé‡ï¼Œè¿™75ä¸ªæƒé‡æ˜¯é€šè¿‡å­¦ä¹ è¿›è¡Œæ›´æ–°çš„ï¼Œæ‰€ä»¥å¾ˆå¤§ç¨‹åº¦ä¸Šè¿™äº›æƒå€¼ä¹‹é—´æ˜¯ä¸ç›¸ç­‰ï¼ˆä¹Ÿå°±å¯¹äºŽåŒä¸€ä¸ªå·ç§¯æ ¸ï¼Œå®ƒå¯¹äºŽä¸Žå®ƒè¿žæŽ¥çš„è¾“å…¥çš„æ¯ä¸€å±‚çš„æƒé‡éƒ½æ˜¯ç‹¬ç‰¹çš„ï¼Œä¸æ˜¯åŒæ ·çš„æƒé‡é‡å¤è¾“å…¥å±‚å±‚æ•°é‚£ä¹ˆå¤šæ¬¡å°±å¯ä»¥çš„ï¼‰ã€‚åœ¨è¿™é‡Œç›¸å½“äºŽå‰é¢çš„æ¯ä¸€ä¸ªå±‚å¯¹åº”ä¸€ä¸ªä¼ ç»Ÿæ„ä¹‰ä¸Šçš„å·ç§¯æ¨¡æ¿ï¼Œæ¯ä¸€å±‚ä¸Žè‡ªå·±å·ç§¯æ¨¡æ¿åšå®Œå·ç§¯ä¹‹åŽï¼Œå†å°†å„ä¸ªå±‚çš„ç»“æžœåŠ èµ·æ¥ï¼Œå†åŠ ä¸Šåç½®ï¼Œæ³¨æ„æ˜¯ä¸€ä¸ªåç½®ï¼Œæ— è®ºè¾“å…¥è¾“å…¥æ•°æ®æ˜¯å¤šå°‘å±‚ï¼Œä¸€ä¸ªå·ç§¯æ ¸å°±å¯¹åº”ä¸€ä¸ªåç½®ã€‚


**æ€»ç»“:**

å·ç§¯å±‚æ˜¯æž„å»ºå·ç§¯ç¥žç»ç½‘ç»œçš„æ ¸å¿ƒå±‚ï¼Œå®ƒäº§ç”Ÿäº†ç½‘ç»œä¸­å¤§éƒ¨åˆ†çš„è®¡ç®—é‡ã€‚æ³¨æ„æ˜¯è®¡ç®—é‡è€Œä¸æ˜¯å‚æ•°é‡ã€‚

**å·ç§¯å±‚çš„ä½œç”¨:**

1. æ»¤æ³¢å™¨çš„ä½œç”¨æˆ–è€…è¯´æ˜¯å·ç§¯çš„ä½œç”¨
2. å¯ä»¥è¢«çœ‹åšæ˜¯ç¥žç»å…ƒçš„ä¸€ä¸ªè¾“å‡º
3. é™ä½Žå‚æ•°çš„æ•°é‡

### 2.2 æ¿€æ´»å‡½æ•°

æ¿€æ´»å‡½æ•°æ˜¯ç”¨æ¥åŠ å…¥éžçº¿æ€§å› ç´ ï¼Œæé«˜ç½‘ç»œè¡¨è¾¾èƒ½åŠ›ï¼Œå·ç§¯ç¥žç»ç½‘ç»œä¸­æœ€å¸¸ç”¨çš„æ˜¯ReLUï¼ŒSigmoidä½¿ç”¨è¾ƒå°‘ã€‚


1. ReLUå‡½æ•°



$$
f(z)=\left\{\begin{array}{cc} 
		z, & if z>=0\\ 
		0, & if z<0\ 
\end{array}\right.
$$


 
ReLUå‡½æ•°çš„ä¼˜ç‚¹ï¼š

- è®¡ç®—é€Ÿåº¦å¿«ï¼ŒReLUå‡½æ•°åªæœ‰çº¿æ€§å…³ç³»ï¼Œæ¯”Sigmoidå’ŒTanhè¦å¿«å¾ˆå¤š
- è¾“å…¥ä¸ºæ­£æ•°çš„æ—¶å€™ï¼Œä¸å­˜åœ¨æ¢¯åº¦æ¶ˆå¤±é—®é¢˜


ReLUå‡½æ•°çš„ç¼ºç‚¹ï¼š

- å¼ºåˆ¶æ€§æŠŠè´Ÿå€¼ç½®ä¸º0ï¼Œå¯èƒ½ä¸¢æŽ‰ä¸€äº›ç‰¹å¾
- å½“è¾“å…¥ä¸ºè´Ÿæ•°æ—¶ï¼Œæƒé‡æ— æ³•æ›´æ–°ï¼Œå¯¼è‡´â€œç¥žç»å…ƒæ­»äº¡â€(å­¦ä¹ çŽ‡ä¸ è¦å¤ªå¤§)

2. Parametric ReLU

$$
f(z)=\left\{\begin{array}{cc} 
		{z}, & if z>=0\\ 
		\alpha{z}, & if  z<0\ 
\end{array}\right.
$$
 
å½“ ð›¼=0.01 æ—¶ï¼Œç§°ä½œLeaky ReLU
å½“ ð›¼ ä»Žé«˜æ–¯åˆ†å¸ƒä¸­éšæœºäº§ç”Ÿæ—¶ï¼Œç§°ä¸ºRandomized ReLU(RReLU)

PReLUå‡½æ•°çš„ä¼˜ç‚¹ï¼š

- æ¯”sigmoid/tanhæ”¶æ•›å¿«
- è§£å†³äº†ReLUçš„â€œç¥žç»å…ƒæ­»äº¡â€é—®é¢˜

PReLUå‡½æ•°çš„ç¼ºç‚¹ï¼šéœ€è¦å†å­¦ä¹ ä¸€ä¸ªå‚æ•°ï¼Œå·¥ä½œé‡å˜å¤§

3. ELUå‡½æ•°

$$
f(z)=\left\{\begin{array}{cc} 
		{z}, & if z>=0\\ 
		\alpha{e^z-1}, & if z<0\ 
\end{array}\right.
$$
 
ELUå‡½æ•°çš„ä¼˜ç‚¹ï¼š

- å¤„ç†å«æœ‰å™ªå£°çš„æ•°æ®æœ‰ä¼˜åŠ¿
- æ›´å®¹æ˜“æ”¶æ•›

ELUå‡½æ•°çš„ç¼ºç‚¹ï¼šè®¡ç®—é‡è¾ƒå¤§ï¼Œæ”¶æ•›é€Ÿåº¦è¾ƒæ…¢

- CNNåœ¨å·ç§¯å±‚å°½é‡ä¸è¦ä½¿ç”¨Sigmoidå’ŒTanhï¼Œå°†å¯¼è‡´æ¢¯åº¦æ¶ˆå¤±ã€‚
- é¦–å…ˆé€‰ç”¨ReLUï¼Œä½¿ç”¨è¾ƒå°çš„å­¦ä¹ çŽ‡ï¼Œä»¥å…é€ æˆç¥žç»å…ƒæ­»äº¡çš„æƒ…å†µã€‚
- å¦‚æžœReLUå¤±æ•ˆï¼Œè€ƒè™‘ä½¿ç”¨Leaky ReLUã€PReLUã€ELUæˆ–è€…Maxoutï¼Œæ­¤æ—¶ä¸€èˆ¬æƒ…å†µéƒ½å¯ä»¥è§£å†³

ç‰¹å¾å›¾

- æµ…å±‚å·ç§¯å±‚ï¼šæå–çš„æ˜¯å›¾åƒåŸºæœ¬ç‰¹å¾ï¼Œå¦‚è¾¹ç¼˜ã€æ–¹å‘å’Œçº¹ç†ç­‰ç‰¹å¾
- æ·±å±‚å·ç§¯å±‚ï¼šæå–çš„æ˜¯å›¾åƒé«˜é˜¶ç‰¹å¾ï¼Œå‡ºçŽ°äº†é«˜å±‚è¯­ä¹‰æ¨¡å¼ï¼Œå¦‚â€œè½¦è½®â€ã€â€œäººè„¸â€ç­‰ç‰¹å¾
    

### 2.3 æ± åŒ–å±‚

æ± åŒ–å±‚ï¼ˆPooling Layerï¼‰ä¹Ÿå«å­é‡‡æ ·å±‚ï¼ˆSubsampling Layerï¼‰ï¼šä¿ƒè¿›ç‰¹å¾é€‰æ‹©ï¼Œé™ä½Žç‰¹å¾/å‚æ•°æ•°é‡ï¼Œé¿å…è¿‡æ‹Ÿåˆ

æ± åŒ–ï¼ˆPoolingï¼‰æ˜¯æŒ‡å¯¹æ¯ä¸ªåŒºåŸŸè¿›è¡Œä¸‹é‡‡æ ·ï¼ˆDown Samplingï¼‰å¾—åˆ°ä¸€ä¸ªå€¼ï¼Œä½œä¸ºè¿™ä¸ªåŒºåŸŸçš„æ¦‚æ‹¬


å¸¸ç”¨æ±‡èšå‡½æ•°ï¼š

1. æœ€å¤§æ±‡èšï¼ˆMaximum Pooling/ Max Poolingï¼‰ï¼š$y\_{m, n}^{d}=\max \_{i \in R\_{m, n}^{d}} x\_{i}$
2. å¹³å‡æ±‡èšï¼ˆMean Poolingï¼‰ï¼š$y\_{m, n}^{d}=\frac{1}{\left|R\_{m, n}^{d}\right|} \sum\_{i \in R\_{m, n}^{d}} x\_{i}$

æ± åŒ–å±‚å¯ä»¥çœ‹ä½œç‰¹æ®Šçš„å·ç§¯å±‚ï¼šå·ç§¯æ ¸å¤§å°ä¸º$K\times K$ï¼Œæ­¥é•¿ä¸º$S\times S$ï¼Œå·ç§¯æ ¸ä¸ºmaxå‡½æ•°æˆ–meanå‡½æ•°

## 3 . ç»å…¸CNN

### 3.1 LeNet-5


æ¥æºè®ºæ–‡ï¼š[LeCun, Yann, et al. â€œGradient-based learning applied to document recognition.â€ Proceedings of the IEEE 86.11 (1998): 2278-2324.](https://ieeexplore.ieee.org/document/726791)

è®ºæ–‡è¯¦è§£ï¼š[CNNå…¥é—¨ç®—æ³•LeNet-5è¯¦è§£](https://www.datalearner.com/blog/1051558664111790)

ä»£ç å®žçŽ°ï¼šhttps://github.com/TaavishThaman/LeNet-5-with-Keras

LeNet-5ä¸»è¦æ˜¯é’ˆå¯¹ç°åº¦è®¾è®¡çš„ï¼Œæ‰€ä»¥å…¶è¾“å…¥è¾ƒå°ï¼Œä¸º $ 32 Ã— 32 Ã— 1 $ ï¼Œå…¶ç»“æž„å¦‚ä¸‹ï¼š


![img](./images/task04-05.jpg)


LeNet-5ç»“æž„è§£è¯»ï¼š

**INPUT($ 32 Ã— 32 $)ï¼š**$32x32$ çš„æ‰‹å†™æ•°å­—çš„å›¾ç‰‡ï¼Œé€šé“ä¸º$1$ ï¼Œç°åº¦å›¾åƒï¼Œ2ç»´çŸ©é˜µï¼Œ`å½©è‰²å›¾åƒä¸‰ä¸ªé€šé“`ã€‚  

**C1ï¼š** C1å±‚ä½¿ç”¨äº†6ä¸ªå¤§å°ä¸º5x5çš„å·ç§¯æ ¸(f=5*5*6)ï¼Œæ­¥é•¿ä¸º1(s=1),å¡«å……ä¸º0(p=0,vailid padding)ã€‚å› æ­¤ï¼Œè¾“å‡ºä¸º28x28x6 $(32+2*0-5)/2 +1 = 28$ã€‚  
**Layer2ï¼š**2x2å¤§å°çš„æ± åŒ–å±‚ï¼ˆf=2ï¼Œs=2ï¼‰ï¼Œä½¿ç”¨çš„æ˜¯average poolingï¼Œæ­¥é•¿ä¸º2ã€‚é‚£ä¹ˆè¿™ä¸€å±‚çš„è¾“å‡ºå°±æ˜¯14x14x6ï¼Œç¼©å°ä¸€åŠã€‚  
**Layer3ï¼š**16ä¸ªå¤§å°ä¸º5x5çš„å·ç§¯æ ¸ï¼Œæ­¥é•¿ä¸º1ï¼Œè¾“å‡ºä¸ºï¼š$10Ã—10Ã—16$ã€‚  
**Layer4ï¼š**å’Œç¬¬äºŒå±‚ä¸€æ ·ï¼Œ2x2å¤§å°çš„æ± åŒ–å±‚ï¼ˆäºŒæ¬¡è‡­æ°§å±‚ï¼‰ï¼Œä½¿ç”¨çš„æ˜¯average poolingï¼Œæ­¥é•¿ä¸º2ã€‚  
**Layer5ï¼š**å·ç§¯å±‚ï¼Œ120ä¸ªå·ç§¯æ ¸ï¼Œå¤§å°ä¸º1x1ã€‚  
**Layer6ï¼š**å…¨è¿žæŽ¥å±‚ï¼Œéšè—å•å…ƒæ˜¯84ä¸ªã€‚  
**Layer7ï¼š**è¾“å‡ºå±‚ï¼Œsoftmax,è¾“å‡ºå•å…ƒæ˜¯10ä¸ªï¼Œå› ä¸ºæ•°å­—è¯†åˆ«æ˜¯0-9ã€‚  


æ€»ç»“ï¼š
- LeNet-5æ˜¯ä¸€ç§ç”¨äºŽæ‰‹å†™ä½“å­—ç¬¦è¯†åˆ«çš„éžå¸¸é«˜æ•ˆçš„å·ç§¯ç¥žç»ç½‘ç»œ,éšç€ç½‘ç»œçš„æ·±åº¦å¢žåŠ ï¼Œå›¾åƒçš„å¤§å°åœ¨ç¼©å°ï¼Œä¸Žæ­¤åŒæ—¶ï¼Œé€šé“çš„æ•°é‡å´åœ¨å¢žåŠ ,æ¯ä¸ªå·ç§¯å±‚åŽé¢æŽ¥ä¸€ä¸ªæ± åŒ–å±‚ã€‚
- å·ç§¯ç¥žç»ç½‘ç»œèƒ½å¤Ÿå¾ˆå¥½çš„åˆ©ç”¨å›¾åƒçš„ç»“æž„ä¿¡æ¯ã€‚
- å·ç§¯å±‚çš„å‚æ•°è¾ƒå°‘ï¼Œè¿™ä¹Ÿæ˜¯ç”±å·ç§¯å±‚çš„ä¸»è¦ç‰¹æ€§å³å±€éƒ¨è¿žæŽ¥å’Œå…±äº«æƒé‡æ‰€å†³å®šã€‚



```python
import tensorflow as tf

def leNet():
    return tf.keras.models.Sequential([
        tf.keras.layers.Conv2D(filters=6, kernel_size=5, activation='sigmoid',
                               padding='valid'),
        tf.keras.layers.AvgPool2D(pool_size=2, strides=2),
        tf.keras.layers.Conv2D(filters=16, kernel_size=5,
                               activation='sigmoid'),
        tf.keras.layers.AvgPool2D(pool_size=2, strides=2),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(120, activation='sigmoid'),
        tf.keras.layers.Dense(84, activation='sigmoid'),
        tf.keras.layers.Dense(10)])

X = tf.random.uniform((1, 32, 32, 1))
for layer in leNet().layers:
    X = layer(X)
    print(layer.__class__.__name__, 'output shape: \t', X.shape)
```

    Conv2D output shape: 	 (1, 28, 28, 6)
    AveragePooling2D output shape: 	 (1, 14, 14, 6)
    Conv2D output shape: 	 (1, 10, 10, 16)
    AveragePooling2D output shape: 	 (1, 5, 5, 16)
    Flatten output shape: 	 (1, 400)
    Dense output shape: 	 (1, 120)
    Dense output shape: 	 (1, 84)
    Dense output shape: 	 (1, 10)
    

**LeNet5**åœ¨MNISTæ•°æ®é›†ä¸Šçš„å®žçŽ°ï¼ŒC1æ”¹ä¸º`same`,å…¶ä»–ä¿æŒä¸€è‡´


```python
from tensorflow.keras.datasets import mnist
from tensorflow.keras.layers import Flatten, Conv2D, MaxPool2D, Dense
from tensorflow.keras.models import Sequential

from tensorflow.keras.optimizers import SGD
from tensorflow.keras.utils import plot_model, to_categorical

import matplotlib.pyplot as plt

(x_train, y_train), (x_test, y_test) = mnist.load_data()

#æ•°æ®å˜æˆTensorFowä¸ºBackendçš„å½¢å¼
x_train=x_train.reshape(60000,28,28,1)
x_test=x_test.reshape(10000,28,28,1)
#æŠŠæ ‡ç­¾å˜æˆone-hotç¼–ç çš„å½¢å¼
y_train=to_categorical(y_train,num_classes=10)
y_test=to_categorical(y_test,num_classes=10)

# æž„å»ºLeNet-5ç½‘ç»œ
model = Sequential()
model.add(Conv2D(input_shape = (28,28,1), filters=6, kernel_size=(5,5), padding='same', activation='tanh'))
model.add(MaxPool2D(pool_size=(2,2), strides=2))
model.add(Conv2D(input_shape=(14,14,6), filters=16, kernel_size=(5,5), padding='valid', activation='tanh'))
model.add(MaxPool2D(pool_size=(2,2), strides=2))
model.add(Flatten())
model.add(Dense(120, activation='tanh'))
model.add(Dense(84, activation='tanh'))
model.add(Dense(10, activation='softmax'))
model.summary()

model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.01), metrics=['accuracy'])
history = model.fit(x_train, y_train, batch_size=128, epochs=30)
print(history.history.keys())


```

    Model: "sequential_12"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_24 (Conv2D)           (None, 28, 28, 6)         156       
    _________________________________________________________________
    max_pooling2d_4 (MaxPooling2 (None, 14, 14, 6)         0         
    _________________________________________________________________
    conv2d_25 (Conv2D)           (None, 10, 10, 16)        2416      
    _________________________________________________________________
    max_pooling2d_5 (MaxPooling2 (None, 5, 5, 16)          0         
    _________________________________________________________________
    flatten_12 (Flatten)         (None, 400)               0         
    _________________________________________________________________
    dense_36 (Dense)             (None, 120)               48120     
    _________________________________________________________________
    dense_37 (Dense)             (None, 84)                10164     
    _________________________________________________________________
    dense_38 (Dense)             (None, 10)                850       
    =================================================================
    Total params: 61,706
    Trainable params: 61,706
    Non-trainable params: 0
    _________________________________________________________________
    Epoch 1/30
    469/469 [==============================] - 16s 33ms/step - loss: 0.8247 - accuracy: 0.8025
    Epoch 2/30
    469/469 [==============================] - 16s 33ms/step - loss: 0.2817 - accuracy: 0.9295
    Epoch 3/30
    469/469 [==============================] - 17s 36ms/step - loss: 0.2023 - accuracy: 0.9462
    Epoch 4/30
    469/469 [==============================] - 15s 33ms/step - loss: 0.1659 - accuracy: 0.9548
    Epoch 5/30
    469/469 [==============================] - 16s 33ms/step - loss: 0.1425 - accuracy: 0.9599
    Epoch 6/30
    469/469 [==============================] - 16s 35ms/step - loss: 0.1275 - accuracy: 0.9644
    Epoch 7/30
    469/469 [==============================] - 16s 34ms/step - loss: 0.1180 - accuracy: 0.9669
    Epoch 8/30
    469/469 [==============================] - 16s 33ms/step - loss: 0.1077 - accuracy: 0.9698
    Epoch 9/30
    469/469 [==============================] - 16s 33ms/step - loss: 0.1022 - accuracy: 0.9717
    Epoch 10/30
    469/469 [==============================] - 16s 33ms/step - loss: 0.0965 - accuracy: 0.9728
    Epoch 11/30
    469/469 [==============================] - 18s 38ms/step - loss: 0.0913 - accuracy: 0.9738
    Epoch 12/30
    469/469 [==============================] - 19s 40ms/step - loss: 0.0869 - accuracy: 0.9751
    Epoch 13/30
    469/469 [==============================] - 19s 40ms/step - loss: 0.0823 - accuracy: 0.9762
    Epoch 14/30
    469/469 [==============================] - 18s 38ms/step - loss: 0.0792 - accuracy: 0.9769
    Epoch 15/30
    469/469 [==============================] - 18s 38ms/step - loss: 0.0760 - accuracy: 0.9782
    Epoch 16/30
    469/469 [==============================] - 18s 39ms/step - loss: 0.0727 - accuracy: 0.9789
    Epoch 17/30
    469/469 [==============================] - 17s 36ms/step - loss: 0.0706 - accuracy: 0.9793
    Epoch 18/30
    469/469 [==============================] - 17s 36ms/step - loss: 0.0683 - accuracy: 0.9804
    Epoch 19/30
    469/469 [==============================] - 16s 34ms/step - loss: 0.0658 - accuracy: 0.9807
    Epoch 20/30
    469/469 [==============================] - 17s 36ms/step - loss: 0.0651 - accuracy: 0.98130s - loss: 0.0650 - accuracy
    Epoch 21/30
    469/469 [==============================] - 16s 35ms/step - loss: 0.0624 - accuracy: 0.9822
    Epoch 22/30
    469/469 [==============================] - 18s 38ms/step - loss: 0.0605 - accuracy: 0.9830
    Epoch 23/30
    469/469 [==============================] - 18s 37ms/step - loss: 0.0591 - accuracy: 0.9831
    Epoch 24/30
    469/469 [==============================] - 17s 36ms/step - loss: 0.0570 - accuracy: 0.9838
    Epoch 25/30
    469/469 [==============================] - 17s 36ms/step - loss: 0.0563 - accuracy: 0.9837
    Epoch 26/30
    469/469 [==============================] - 18s 38ms/step - loss: 0.0542 - accuracy: 0.9844
    Epoch 27/30
    469/469 [==============================] - 17s 37ms/step - loss: 0.0529 - accuracy: 0.9847
    Epoch 28/30
    469/469 [==============================] - 17s 37ms/step - loss: 0.0523 - accuracy: 0.9848
    Epoch 29/30
    469/469 [==============================] - 17s 36ms/step - loss: 0.0516 - accuracy: 0.9854
    Epoch 30/30
    469/469 [==============================] - 16s 33ms/step - loss: 0.0502 - accuracy: 0.9856
    dict_keys(['loss', 'accuracy'])
    


```python
# summarize history for accuracy
plt.plot(history.history['loss'])
plt.plot(history.history['accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['loss','acc'], loc='upper left')
plt.show()
```

![img](./images/task04-LeNet5-acc.png)

### 3.2 AlexNet

æ¥æºè®ºæ–‡ï¼š[Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. 
â€œImagenet classification with deep convolutional neural networks.â€ Advances in neural information processing systems. 2012.](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)

è®ºæ–‡è¯¦è§£ï¼š[CNNç»å…¸ç®—æ³•AlexNetä»‹ç»](https://www.datalearner.com/blog/1051558919769185)

ä»£ç å®žçŽ°ï¼š
1. https://github.com/hjptriplebee/AlexNet_with_tensorflow
2. https://github.com/TaavishThaman/LeNet-5-with-Keras

![img](./images/task04-AlexNet.jpg)

ç½‘ç»œç»“æž„è¯´æ˜Ž  
- è¾“å…¥å±‚ï¼šå›¾åƒå¤§å°ä¸º 227Ã—227Ã—3ï¼Œå…¶ä¸­ 3 è¡¨ç¤ºè¾“å…¥å›¾åƒçš„ channel æ•°ï¼ˆRï¼ŒGï¼ŒBï¼‰ä¸º 3ã€‚
- å·ç§¯å±‚ï¼šfilterå¤§å°11113ï¼Œs=4ï¼Œä¸ªæ•°ä¸º96ä¸ª
- æ± åŒ–å±‚ï¼šfilterä¸º33ï¼Œs= 2ï¼Œé‡‡ç”¨æœ€å¤§æ± åŒ–
- å·ç§¯å±‚ï¼šfilter å¤§å° 5Ã—5ï¼Œ ä¸ªæ•° 256ï¼Œæ­¥é•¿ s=1ï¼Œpadding ä½¿ç”¨sameï¼Œä½¿å¾—å·ç§¯å±‚è¾“å‡ºå›¾åƒå’Œè¾“å…¥å›¾åƒåœ¨å®½å’Œé«˜ä¸Šä¿æŒä¸å˜
ï¼ˆå¦å¤–æœ‰validã€fullï¼Œå…·ä½“å¯å‚è€ƒpaddingçš„ä¸‰ç§æ¨¡å¼ï¼‰
- æ± åŒ–å±‚ï¼šmax poolingï¼Œfilter å¤§å° 3Ã—3ï¼Œæ­¥é•¿ s=2
- å·ç§¯å±‚ï¼šfilter å¤§å° 3Ã—3ï¼Œfilter ä¸ªæ•° 384ï¼Œæ­¥é•¿ s=1ï¼Œpadding ä½¿ç”¨ same
- å·ç§¯å±‚ï¼šfilter å¤§å° 3Ã—3ï¼Œfilter ä¸ªæ•° 384ï¼Œæ­¥é•¿ s=1ï¼Œpadding ä½¿ç”¨ same
- å·ç§¯å±‚ï¼šfilter å¤§å° 3Ã—3ï¼Œfilter ä¸ªæ•° 256ï¼Œæ­¥é•¿ s=1ï¼Œpadding ä½¿ç”¨ same
- æ± åŒ–å±‚ï¼šmax poolingï¼Œfilter å¤§å° 3Ã—3ï¼Œæ­¥é•¿ s=2ï¼›æ± åŒ–æ“ä½œç»“æŸåŽï¼Œå°†å¤§å°ä¸º 6Ã—6Ã—256 çš„è¾“å‡ºçŸ©é˜µæŽ’åˆ—æˆä¸€ä¸ª9216 ç»´çš„å‘é‡ã€‚
- å…¨è¿žæŽ¥å±‚ï¼šneuron æ•°é‡ä¸º 4096ã€‚
- å…¨è¿žæŽ¥å±‚ï¼šneuron æ•°é‡ä¸º 4096ã€‚
- å…¨è¿žæŽ¥å±‚ï¼Œè¾“å‡ºå±‚ï¼šsoftmax æ¿€æ´»å‡½æ•°ï¼Œneuron æ•°é‡ä¸º 1000ï¼Œä»£è¡¨ 1000 ä¸ªç±»åˆ«ã€‚


ç‰¹ç‚¹ï¼š

- AlexNet æ¨¡åž‹ä¸Ž LeNet-5 æ¨¡åž‹ç±»ä¼¼ï¼Œä½†æ˜¯æ›´å¤æ‚ï¼ŒåŒ…å«çº¦ 6000 ä¸‡ä¸ªå‚æ•°ã€‚å¦å¤–ï¼ŒAlexNet æ¨¡åž‹ä½¿ç”¨äº† ReLU å‡½æ•°ã€‚
- å½“ç”¨äºŽè®­ç»ƒå›¾åƒå’Œæ•°æ®é›†æ—¶ï¼ŒAlexNet èƒ½å¤Ÿå¤„ç†éžå¸¸ç›¸ä¼¼çš„åŸºæœ¬æž„é€ æ¨¡å—ï¼Œè¿™äº›æ¨¡å—å¾€å¾€åŒ…å«å¤§é‡çš„éšè—å•å…ƒæˆ–æ•°æ®ã€‚






```python
from tensorflow.keras.datasets import mnist
from tensorflow.keras.layers import Flatten, Conv2D, MaxPool2D, Dense
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import BatchNormalization,Dropout
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.utils import plot_model, to_categorical

import matplotlib.pyplot as plt

# æž„å»ºAlexNet-5ç½‘ç»œ
model = Sequential()
model.add(Conv2D(input_shape = (227,227,3), strides = 4, filters=96, kernel_size=(11,11), padding='valid', activation='relu'))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size=(3,3), strides=2))
model.add(Conv2D(filters=256, kernel_size=(5,5), padding='same', activation='relu'))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size=(3,3), strides=2))
model.add(Conv2D(filters=384, kernel_size=(3,3), padding='same', activation='relu'))
model.add(BatchNormalization())
model.add(Conv2D(filters=384, kernel_size=(3,3), padding='same', activation='relu'))
model.add(BatchNormalization())
model.add(Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu'))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size=(2,2), strides=2))
model.add(Flatten())
model.add(Dense(4096, activation='tanh'))
model.add(Dropout(0.5))
model.add(Dense(4096, activation='tanh'))
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))
model.summary()
```

    Model: "sequential_16"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_34 (Conv2D)           (None, 55, 55, 96)        34944     
    _________________________________________________________________
    batch_normalization_5 (Batch (None, 55, 55, 96)        384       
    _________________________________________________________________
    max_pooling2d_9 (MaxPooling2 (None, 27, 27, 96)        0         
    _________________________________________________________________
    conv2d_35 (Conv2D)           (None, 27, 27, 256)       614656    
    _________________________________________________________________
    batch_normalization_6 (Batch (None, 27, 27, 256)       1024      
    _________________________________________________________________
    max_pooling2d_10 (MaxPooling (None, 13, 13, 256)       0         
    _________________________________________________________________
    conv2d_36 (Conv2D)           (None, 13, 13, 384)       885120    
    _________________________________________________________________
    batch_normalization_7 (Batch (None, 13, 13, 384)       1536      
    _________________________________________________________________
    conv2d_37 (Conv2D)           (None, 13, 13, 384)       1327488   
    _________________________________________________________________
    batch_normalization_8 (Batch (None, 13, 13, 384)       1536      
    _________________________________________________________________
    conv2d_38 (Conv2D)           (None, 13, 13, 256)       884992    
    _________________________________________________________________
    batch_normalization_9 (Batch (None, 13, 13, 256)       1024      
    _________________________________________________________________
    max_pooling2d_11 (MaxPooling (None, 6, 6, 256)         0         
    _________________________________________________________________
    flatten_15 (Flatten)         (None, 9216)              0         
    _________________________________________________________________
    dense_43 (Dense)             (None, 4096)              37752832  
    _________________________________________________________________
    dropout (Dropout)            (None, 4096)              0         
    _________________________________________________________________
    dense_44 (Dense)             (None, 4096)              16781312  
    _________________________________________________________________
    dropout_1 (Dropout)          (None, 4096)              0         
    _________________________________________________________________
    dense_45 (Dense)             (None, 10)                40970     
    =================================================================
    Total params: 58,327,818
    Trainable params: 58,325,066
    Non-trainable params: 2,752
    _________________________________________________________________
    

### 3.3 Inceptionç½‘ç»œ

Inception-v1(GoogLeNet)

æ¥æºè®ºæ–‡ï¼š[Szegedy, Christian, et al. â€œGoing deeper with convolutions.â€ Proceedings of the IEEE conference on computer vision and pattern recognition. 2015.](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf)

è®ºæ–‡è¯¦è§£ï¼š[CNNç»å…¸ç®—æ³•ä¹‹Inception V1ï¼ˆGoogLeNetï¼‰](https://www.datalearner.com/blog/1051559096989577)

ä»£ç å’Œé¢„è®­ç»ƒèµ„æºï¼š[GoogLeNetä»£ç èµ„æºï¼ˆTensorflowï¼‰](https://github.com/conan7882/GoogLeNet-Inception)


**å®Œæ•´çš„ Inception ç½‘ç»œ**

![img](./images/task04-Inception.jpg)


ä¸Šå›¾æ˜¯å¼•å…¥ 1x1 å·ç§¯åŽçš„ Inception æ¨¡å—ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä¸ºäº†å°†æ‰€æœ‰çš„è¾“å‡ºç»„åˆèµ·æ¥ï¼Œçº¢è‰²çš„æ± åŒ–å±‚ä½¿ç”¨ Same ç±»åž‹çš„å¡«å……ï¼ˆpaddingï¼‰æ¥æ± åŒ–ä½¿å¾—è¾“å‡ºçš„å®½é«˜ä¸å˜ï¼Œé€šé“æ•°ä¹Ÿä¸å˜ã€‚

å¤šä¸ª Inception æ¨¡å—ç»„æˆä¸€ä¸ªå®Œæ•´çš„ Inception ç½‘ç»œï¼ˆè¢«ç§°ä¸º GoogLeNetï¼Œä»¥å‘ LeNet è‡´æ•¬ï¼‰ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![img](./images/task04-Inception-network.jpg)

æ³¨æ„é»‘è‰²æ¤­åœ†åœˆå‡ºçš„éšè—å±‚ï¼Œè¿™äº›åˆ†æ”¯éƒ½æ˜¯ Softmax çš„è¾“å‡ºå±‚ï¼Œå¯ä»¥ç”¨æ¥å‚ä¸Žç‰¹å¾çš„è®¡ç®—åŠç»“æžœé¢„æµ‹ï¼Œèµ·åˆ°è°ƒæ•´å¹¶é˜²æ­¢å‘ç”Ÿè¿‡æ‹Ÿåˆçš„æ•ˆæžœã€‚

ç»è¿‡ç ”ç©¶è€…ä»¬çš„ä¸æ–­å‘å±•ï¼ŒInception æ¨¡åž‹çš„ V2ã€V3ã€V4 ä»¥åŠå¼•å…¥æ®‹å·®ç½‘ç»œçš„ç‰ˆæœ¬è¢«æå‡ºï¼Œè¿™äº›å˜ä½“éƒ½åŸºäºŽ Inception V1 ç‰ˆæœ¬çš„åŸºç¡€æ€æƒ³ä¸Šã€‚


### 3.4 VGG-16

ç›¸å…³è®ºæ–‡ï¼š[Simonvan & Zisserman 2015. Very deep convolutional networks for large-scale image recognitionã€‚](https://arxiv.org/pdf/1409.1556.pdf)


è®ºæ–‡è¯¦è§£ï¼š[CNNç»å…¸ç®—æ³•VGGNetä»‹ç»](https://www.datalearner.com/blog/1051558603213207#google_vignette)

ä»£ç å’Œé¢„è®­ç»ƒèµ„æºï¼š[VGGNeté¢„è®­ç»ƒæ¨¡åž‹åŠä»£ç èµ„æº](https://www.datalearner.com/blog/1051559048634862#%E5%9B%9B%E3%80%81VGGNet%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%8F%8A%E4%BB%A3%E7%A0%81%E8%B5%84%E6%BA%90)



VGGå·ç§¯å±‚å’Œæ± åŒ–å±‚å‡å…·æœ‰ç›¸åŒçš„å·ç§¯æ ¸å¤§å°ï¼Œéƒ½ä½¿ç”¨ $ 3 Ã— 3ï¼Œstrdie = 1, SAME $ çš„å·ç§¯å’Œ $ 2  Ã— 2ï¼Œstride = 2 $ çš„æ± åŒ–ã€‚


![img](./images/task04-VGG16.png)

ç»“æž„

å‚ç…§å›¾ä¸­

VGG-16ç½‘ç»œç»“æž„å¾ˆè§„æ•´ï¼Œæ²¡æœ‰é‚£ä¹ˆå¤šçš„è¶…å‚æ•°ï¼Œä¸“æ³¨äºŽæž„å»ºç®€å•çš„ç½‘ç»œï¼Œéƒ½æ˜¯å‡ ä¸ªå·ç§¯å±‚åŽé¢è·Ÿä¸€ä¸ªå¯ä»¥åŽ‹ç¼©å›¾åƒå¤§å°çš„æ± åŒ–å±‚ã€‚


ç‰¹ç‚¹ï¼š

- VGG åˆç§° VGG-16 ç½‘ç»œï¼Œâ€œ16â€æŒ‡ç½‘ç»œä¸­åŒ…å« 16 ä¸ªå·ç§¯å±‚å’Œå…¨è¿žæŽ¥å±‚ã€‚
- è¶…å‚æ•°è¾ƒå°‘ï¼Œåªéœ€è¦ä¸“æ³¨äºŽæž„å»ºå·ç§¯å±‚ã€‚
- ç»“æž„ä¸å¤æ‚ä¸”è§„æ•´ï¼Œåœ¨æ¯ä¸€ç»„å·ç§¯å±‚è¿›è¡Œæ»¤æ³¢å™¨ç¿»å€æ“ä½œã€‚
- VGG éœ€è¦è®­ç»ƒçš„ç‰¹å¾æ•°é‡å·¨å¤§ï¼ŒåŒ…å«å¤šè¾¾çº¦ 1.38 äº¿ä¸ªå‚æ•°ã€‚

### 3.5 æ®‹å·®ç½‘ç»œ

å› ä¸ºå­˜åœ¨æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸é—®é¢˜ï¼Œç½‘ç»œè¶Šæ·±ï¼Œå°±è¶Šéš¾ä»¥è®­ç»ƒæˆåŠŸã€‚æ®‹å·®ç½‘ç»œï¼ˆResidual Networksï¼Œç®€ç§°ä¸º ResNetsï¼‰å¯ä»¥æœ‰æ•ˆè§£å†³è¿™ä¸ªé—®é¢˜ã€‚



æ™®é€šçš„ç¥žç»ç½‘ç»œå—çš„ä¼ è¾“ï¼š

![img](./images/task04-vsnet-01.png)

å…¶å‰å‘ä¼ æ’­çš„è®¡ç®—æ­¥éª¤ä¸ºï¼š

- Linear: $ z^{[l+1]} = W^{[l+1]}a^{l} + b^{[l+1]}$
- Relu: $ a^{[l+1]} = g(z^{[l+1]})$
- Linear: $ z^{[l+2]} = W^{[l+2]}a^{l+l} + b^{[l+2]}$
- Relu: $ a^{[l+2]} = g(z^{[l+2]})$


ResNetæ˜¯ç”±æ®‹å·®å—æ‰€æž„å»ºã€‚

æ®‹å·®å—ï¼š

![img](./images/Residual-block.jpg)

ä¸Šå›¾çš„ç»“æž„è¢«ç§°ä¸º**æ®‹å·®å—ï¼ˆResidual blockï¼‰**ã€‚é€šè¿‡**æ·å¾„ï¼ˆShort cutï¼Œæˆ–è€…ç§°è·³è¿œè¿žæŽ¥ï¼ŒSkip connectionsï¼‰**å¯ä»¥å°† $a^{[l]}$æ·»åŠ åˆ°ç¬¬äºŒä¸ª **ReLU** è¿‡ç¨‹ä¸­ï¼Œç›´æŽ¥å»ºç«‹ $a^{[l]}$ä¸Ž $a^{[l+2]}$ ä¹‹é—´çš„éš”å±‚è”ç³»ã€‚è¡¨è¾¾å¼å¦‚ä¸‹ï¼š

$$
z^{l+1} = W^{[l+1]} + b^{[l+1]}\\
a^{l+1} = g(z^{l+1})\\
z^{l+2} = W^{[l+2]}a^{[l+1]} + b^{[l+2]}\\
a^{l+2} = g(z^{l+2} + a^{[l]})
$$

æž„å»ºä¸€ä¸ªæ®‹å·®ç½‘ç»œå°±æ˜¯å°†è®¸å¤šæ®‹å·®å—å †ç§¯åœ¨ä¸€èµ·ï¼Œå½¢æˆä¸€ä¸ªæ·±åº¦ç½‘ç»œã€‚

![img](./images/task04-Residual-Network.jpg)

ä¸ºäº†ä¾¿äºŽåŒºåˆ†ï¼Œåœ¨ ResNets çš„è®ºæ–‡[He et al., 2015. Deep residual networks for image recognition](https://arxiv.org/pdf/1512.03385.pdf)ä¸­ï¼Œéžæ®‹å·®ç½‘ç»œè¢«ç§°ä¸º**æ™®é€šç½‘ç»œï¼ˆPlain Networkï¼‰**ã€‚å°†å®ƒå˜ä¸ºæ®‹å·®ç½‘ç»œçš„æ–¹æ³•æ˜¯åŠ ä¸Šæ‰€æœ‰çš„è·³è¿œè¿žæŽ¥ã€‚


åœ¨ç†è®ºä¸Šï¼Œéšç€ç½‘ç»œæ·±åº¦çš„å¢žåŠ ï¼Œæ€§èƒ½åº”è¯¥è¶Šæ¥è¶Šå¥½ã€‚ä½†å®žé™…ä¸Šï¼Œå¯¹äºŽä¸€ä¸ª**æ™®é€šç½‘ç»œ**ï¼Œéšç€ç¥žç»ç½‘ç»œå±‚æ•°å¢žåŠ ï¼Œè®­ç»ƒé”™è¯¯ä¼šå…ˆå‡å°‘ï¼Œç„¶åŽå¼€å§‹å¢žå¤šã€‚ä½†æ®‹å·®ç½‘ç»œçš„è®­ç»ƒæ•ˆæžœæ˜¾ç¤ºï¼Œå³ä½¿ç½‘ç»œå†æ·±ï¼Œå…¶åœ¨è®­ç»ƒé›†ä¸Šçš„è¡¨çŽ°ä¹Ÿä¼šè¶Šæ¥è¶Šå¥½ã€‚


![img](./images/task04-ResNet-Training-Error.jpg)

æ®‹å·®ç½‘ç»œæœ‰åŠ©äºŽè§£å†³æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸é—®é¢˜ï¼Œä½¿å¾—åœ¨è®­ç»ƒæ›´æ·±çš„ç½‘ç»œçš„åŒæ—¶ï¼Œåˆèƒ½ä¿è¯è‰¯å¥½çš„æ€§èƒ½ã€‚

**æ®‹å·®ç½‘ç»œï¼ˆResidual Networkï¼ŒResNetï¼‰ï¼š**é€šè¿‡ç»™éžçº¿æ€§çš„å·ç§¯å±‚å¢žåŠ ç›´è¿žè¾¹ï¼ˆShortcut Connectionï¼‰ï¼ˆä¹Ÿç§°ä¸ºæ®‹å·®è¿žæŽ¥ Residual Connectionï¼‰ï¼‰çš„æ–¹å¼æ¥æé«˜ä¿¡æ¯çš„ä¼ æ’­æ•ˆçŽ‡

å°†ç›®æ ‡å‡½æ•°æ‹†åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼šæ’ç­‰å‡½æ•°ï¼ˆIdentity Functionï¼‰å’Œæ®‹å·®å‡½æ•°ï¼ˆResidue Functionï¼‰ï¼š

$$
h(\boldsymbol{x})=\underbrace{\boldsymbol{x}}\_{\text {æ’ç­‰å‡½æ•° }}+\underbrace{(h(\boldsymbol{x})-\boldsymbol{x})}\_{\text {æ®‹å·®å‡½æ•° }}
$$
					


## å‚è€ƒèµ„æ–™

- [å´æ©è¾¾æ·±åº¦å­¦ä¹ ç¬”è®°](https://kyonhuang.top/Andrew-Ng-Deep-Learning-notes/#/)
- [åŠ¨æ‰‹å­¦ä¹ æ·±åº¦å­¦ä¹ ](https://zh-v2.d2l.ai/chapter_convolutional-neural-networks/lenet.html)


```python

```
