# 第28期 NLP课程（Transformer）

---

### 

### 目录

- [Task01：熟悉规则，学习概览](docs/transformers_NLP_28/task01.md)
- [Task02：学习Attention和Transformer](docs/transformers_NLP_28/task02.md)
- [Task03：学习BERT和GPT](docs/transformers_NLP_28/task03.md)
- [Task04：编写BERT模型](docs/transformers_NLP_28/task04.md)
- [Task05：BERT应用到下游任务、训练和优化](docs/transformers_NLP_28/task05.md)
- [Task06：Transformers解决文本分类任务、超参搜索](docs/transformers_NLP_28/task06.md)
- [Task07：Transformers解析序列标注任务](docs/transformers_NLP_28/task07.md)
- [Task08：Transformers解决抽取式问答任务](docs/transformers_NLP_28/task08.md)
- [Task09：Transformers解决机器翻译任务](docs/transformers_NLP_28/task09.md)

### 资料

- [Transformer面试题解析](docs/transformers_NLP_28/question.md)
- [[基于transformers的自然语言处理(NLP)入门](https://datawhalechina.github.io/learn-nlp-with-transformers/)](https://datawhalechina.github.io/learn-nlp-with-transformers/#/)

### 主要贡献者

[@ 蔡-Choi-恒者行远](https://github.com/caioo0)
