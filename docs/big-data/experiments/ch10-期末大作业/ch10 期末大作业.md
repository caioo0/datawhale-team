# Chapter10 期中大作业

> 边圣陶，蒋志政，王洲烽

> &emsp;&emsp;本章节对前三章的内容掌握程度进行一个小小的测试，包括一些面向企业的面试题，和基础的实战编程题。也算作最后的收尾工作，以实战作为我们课程的结束。

## 10. 1 面试题

### 10.1.1 hive外部表和内部表的区别

### 10.1.2 简述对Hive桶的理解？

### 10.1.3 HBase和Hive的区别？

### 10.1.4 简述Spark宽窄依赖

### 10.1.5 Hadoop和Spark的相同点和不同点

### 10.1.6 Spark为什么比MapReduce块？

### 10.1.7 说说你对Hadoop生态的认识

## 10.2 实战

从新闻文章中发现热门话题和趋势话题是舆论监督的一项重要任务。在这个项目中，你的任务是使用新闻数据集进行文本数据分析，使用 Python 中 pySpark 的 RDD 和 DataFrame 的 API。问题是计算新闻文章数据集中每年各词的权重，然后选择每年 top-**k**个最重要的词。

**PS：解决方案源码填空示例与结果验证数据在`\juicy-bigdata\experiments\10 期末大作业`目录下**

**同时提前安装`pyspark`包**

### 10.2.1 数据集

您将使用的数据集包含多年来发布的新闻标题数据。在这个文本文件中，每一行都是一篇新闻文章的标题，格式为“ date,term1 term2... ...”。日期和文本用逗号分隔，文本用空格字符分隔。示例文件如下:

```
20030219,council chief executive fails to secure position
20030219,council welcomes ambulance levy decision
20030219,council welcomes insurance breakthrough
20030219,fed opp to re introduce national insurance
20040501,cowboys survive eels comeback
20040501,cowboys withstand eels fightback
20040502,castro vows cuban socialism to survive bush
20200401,coronanomics things learnt about how coronavirus economy
20200401,coronavirus at home test kits selling in the chinese community
20200401,coronavirus campbell remess streams bear making classes
20201015,coronavirus pacific economy foriegn aid china
20201016,china builds pig apartment blocks to guard against swine flu
```

### 10.2.2 文本权重计算

您需要忽略诸如“ to”、“ the”和“ in”之类的停用词。该文件存储了停用词。

为了计算一个文本的为期一年的权重，请使用 TF/IDF 模型。具体而言，TF 和 IDF 可计算为:

$TF(文本 t, 年份 y) = 在 y 年份中，包含文本 t 的新闻标题数量$

$IDF(文本 t,数据集 D) = log10 (在数据集D中年份的总数/含有文本t的年份总数) $

最后，文本 t 对于年份 y 的权重计算如下:

$Weight(文本 t, 年份 y, 数据集 D) = TF(文本 t, 年份 y)* IDF(文本 t, 数据集 D) $

请使用 `import math` 并使用 `math.log10()`计算文本权重，并将结果四舍五入到小数点后6位。

### 10.2.3 输出格式

如果数据集中有 N 年，那么您应该在最终输出文件中输出正好 N 行，并且这些行按年份升序排序。在每一行中，您需要以`<term, weight> `的格式输出 k 对list，并且这些对按照文本权重降序排序。如果两个文本具有相同的权重，则按字母顺序对它们进行排序。具体来说，每行的格式类似于:
“year**\t** Term1,Weight1;Term 2,Weight2;… …;Termk,Weightk” 。例如，给定上述数据集和 **k** = 3，输出应该是:

```
2003 council,1.431364;insurance,0.954243;welcomes,0.954243
2004 cowboys,0.954243;eels,0.954243;survive,0.954243
2020 coronavirus,1.908485;china,0.954243;economy,0.954243
```

### 10.2.4 运行指令

**Dataframe:**

```
spark-submit project_df.py file:///testcase_top_20/sample.txt file:///res_df file:///stopwords.txt k
```

**RDD:**

```
spark-submit project_rdd.py file:///testcase_top_20/sample.txt file:///res_rdd file:///stopwords.txt k
```

其中 `file://`后跟随本地文件目录地址。

> 看到这里的小伙伴们，我们的课程终于结束啦，给坚持这么久的自己点个赞鼓鼓掌，希望你能永远保持开源学习的动力，这也是我们的初衷。
